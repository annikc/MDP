{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import analysis as e2\n",
    "from fxns import running_mean\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plt.cm.Set1.colors\n",
    "\n",
    "def plot_reward(data_collection, labels, expt = 0, smoothing = 100, **kwargs):\n",
    "    '''\n",
    "    data_collection: datafilter class \n",
    "    TODO: need to specify which data --currently only training data\n",
    "    '''\n",
    "    title = kwargs.get('title', ' ')\n",
    "    plt.figure()\n",
    "    for i, sep in enumerate(data_collection):\n",
    "        dat = sep.get_expt_data(expt_type=expt)\n",
    "        for ii, d in enumerate(dat):\n",
    "            if ii == 0:\n",
    "                plt.plot(running_mean(d['total_reward'], smoothing), c=colors[i], label=labels[i])\n",
    "            else:\n",
    "                plt.plot(running_mean(d['total_reward'], smoothing), c=colors[i])\n",
    "    plt.legend(bbox_to_anchor=(1.05,0.95))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "class single_record(object):\n",
    "    def __init__(self, save_id):\n",
    "        parent_dir = './data/'\n",
    "        self.data = pickle.load(open(parent_dir + f'results/{save_id}_data.p', 'rb'))\n",
    "\n",
    "def scale_reward(df_obj):\n",
    "    scaled_r = []\n",
    "    for i in range(len(df_obj.info)):\n",
    "        scaled_r.append([])\n",
    "        target = eval(df_obj.info.iloc[i]['rewards'].strip('{}').split(':')[0])\n",
    "        starts = df_obj.data[i]['starts']\n",
    "        nevents = int(df_obj.info.iloc[i]['num_events'])\n",
    "\n",
    "        for ind, start in enumerate(starts):\n",
    "            steps_from_target = abs(target[0]-start[0]) + abs(target[1]-start[1])\n",
    "            theoretical_max = (nevents-steps_from_target)/2\n",
    "            scaled_r[i].append(df_obj.data[i]['total_reward'][ind]/theoretical_max)\n",
    "    \n",
    "    return scaled_r\n",
    "\n",
    "def scale_reward_single(data_obj, target):\n",
    "    scaled_r = []\n",
    "    starts = data_obj['starts'][0:-2]\n",
    "    for ind, start in enumerate(starts):\n",
    "        nevents = data_obj['trial_length'][ind]\n",
    "        steps_from_target = abs(target[0]-start[0]) + abs(target[1]-start[1])\n",
    "        theoretical_max = (nevents-steps_from_target)/2\n",
    "        scaled_r.append(data_obj['total_reward'][ind]/theoretical_max)\n",
    "\n",
    "    return scaled_r\n",
    "\n",
    "def plot_train_test(ax, training_data, testing_data_set, smooth=False, smoothing=100, **kwargs):\n",
    "    labels = kwargs.get('labels', None)\n",
    "    savetitle = kwargs.get('savetitle', None)\n",
    "    if labels != None:\n",
    "        if len(labels) != len(testing_data_set):\n",
    "            raise Exception('Not Enough Labels For Data')\n",
    "    ## this is a data filter\n",
    "    if smooth:\n",
    "        train = running_mean(training_data, smoothing)\n",
    "    else:\n",
    "        train = training_data\n",
    "    ax.plot(train)\n",
    "\n",
    "    offset = len(training_data)\n",
    "    for ind, testing_data in enumerate(testing_data_set):\n",
    "        testing_reshape = np.zeros(offset + len(testing_data))\n",
    "        testing_reshape[0:offset] = np.nan\n",
    "        if smooth: \n",
    "            test = running_mean(testing_data, smoothing)\n",
    "        else:\n",
    "            test = testing_data\n",
    "        testing_reshape[offset:(offset + len(test))] = test\n",
    "        if labels != None:\n",
    "            ax.plot(testing_reshape, label=labels[ind])\n",
    "        else:\n",
    "            ax.plot(testing_reshape)\n",
    "    ax.legend(bbox_to_anchor = (1.05, 0.95))\n",
    "    ax.set_xlim([0-smoothing,len(testing_reshape)-smoothing-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train6 = single_record('59b3078f-d50e-4011-93e4-f18d65133ac1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n",
      "3\n",
      "7500\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cdb24e983602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "for i in train6.data.keys():\n",
    "    print(len(train6.data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = './data/'\n",
    "df = pd.read_csv(parent_dir + 'sep2020.csv')\n",
    "experiment_types = ['Training',\n",
    "                    'MF Only',\n",
    "                    'EC ($\\psi$)',\n",
    "                    'EC ($\\phi$)',\n",
    "                    'MF Only (free)',\n",
    "                    'EC ($\\psi$)(free)',\n",
    "                    'EC ($\\phi$)(free)' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = e2.DataFilter(df, expt_type=[0], env_type=['None'], arch=['A'], action_list=[\"['Down', 'Up', 'Right', 'Left']\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, x in enumerate(training.data):\n",
    "    dat = running_mean(x['total_reward'],100)\n",
    "    num_actions = len(training.info.iloc[ind]['action_list'].strip('[]').split(','))\n",
    "    plt.plot(dat, label = f'{num_actions} actions' )\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(1.05,0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act4_training_data = training.data[0]\n",
    "act6_training_data = training.data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(act6_training_data['total_reward'])\n",
    "ax.plot(running_mean(act6_training_data_training_data, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_r = e2.DataFilter(df, expt_type=[4], env_type=['None'], arch=['A'])\n",
    "EC_r = e2.DataFilter(df, expt_type=[5], env_type=['None'], arch=['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_r.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1,sharex=True)\n",
    "plot_train_test(ax[1], act4_training_data['total_reward'], [MF_r.data[0]['total_reward'], EC_r.data[0]['total_reward']], smooth=True, labels=['MF', 'EC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_p = e2.DataFilter(df, expt_type=[14], env_type=['None'], arch=['A'])\n",
    "EC_p = e2.DataFilter(df, expt_type=[15], env_type=['None'], arch=['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "plot_train_test(act6_training_data['total_reward'], [MF_p.data[ind]['total_reward'], EC_p.data[ind]['total_reward']], smooth=True, labels=[MF_p.info.iloc[ind]['save_id'], 'EC'],savetitle='../../../Writing/Presentations/Figs/committee4/act6_pshift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7110ef7cf8>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = e2.DataFilter(df, expt_type=[0])\n",
    "MF = e2.DataFilter(df, expt_type=[4])\n",
    "EC = e2.DataFilter(df, expt_type=[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing = 100\n",
    "plt.figure()\n",
    "plt.plot(running_mean(training.data[0]['total_reward'],smoothing), 'gray', label='MF Training')\n",
    "offset = len(training.data[0]['total_reward'])\n",
    "\n",
    "smoothed_MF = running_mean(MF.data[0]['total_reward'][0:5000],smoothing)\n",
    "plt.plot(np.arange(len(smoothed_MF))+offset, smoothed_MF ,label='MF Only')\n",
    "for j in range(2,9,3):\n",
    "    i = j\n",
    "    smoothed_EC = running_mean(EC.data[i]['total_reward'], smoothing)\n",
    "    plt.plot(np.arange(len(smoothed_EC))+offset, smoothed_EC, label=f\"EC (T = {EC.info.iloc[i]['mem_temp']})\", alpha=0.5)\n",
    "plt.legend(bbox_to_anchor=(1.05,0.995))\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EC_test = single_record('f8e89cf3-a8a8-4b5c-9708-46719d0bb806')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = e2.DataFilter(df, expt_type=[0])\n",
    "R_shift_MF_null = e2.DataFilter(df, expt_type=[4], load_from=['0deeec74-183d-4694-a3d2-495d03d20b46'])\n",
    "R_shift_MF_SR   = e2.DataFilter(df, expt_type=[4], load_from=['016375f6-eb4f-46b5-8ce1-80a6ad0ad603'])\n",
    "R_shift_EC_null = e2.DataFilter(df, expt_type=[5], load_from=['0deeec74-183d-4694-a3d2-495d03d20b46'])\n",
    "R_shift_EC_SR   = e2.DataFilter(df, expt_type=[5], load_from=['016375f6-eb4f-46b5-8ce1-80a6ad0ad603'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_shift_MF_null = e2.DataFilter(df, expt_type=[14], load_from=['8f738297-7055-49ef-9cfc-c951d269a48f'])\n",
    "P_shift_MF_SR = e2.DataFilter(df, expt_type=[14], load_from=['59b3078f-d50e-4011-93e4-f18d65133ac1'])\n",
    "P_shift_EC_null = e2.DataFilter(df, expt_type=[15], load_from=['8f738297-7055-49ef-9cfc-c951d269a48f'])\n",
    "P_shift_EC_SR = e2.DataFilter(df, expt_type=[15], load_from=['59b3078f-d50e-4011-93e4-f18d65133ac1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_null = [R_shift_MF_null.data[0]['total_reward'], \n",
    "                  R_shift_EC_null.data[0]['total_reward'],\n",
    "                  P_shift_MF_null.data[0]['total_reward'],\n",
    "                  P_shift_EC_null.data[0]['total_reward']]\n",
    "plot_train_test(training.data[1]['total_reward'], test_data_null, labels=['R - MF', 'R - EC', 'P - MF','P - EC'], smooth=True, savetitle='No SR') # arch A noSR\n",
    "\n",
    "\n",
    "test_data_SR = [R_shift_MF_SR.data[0]['total_reward'][0:5000], \n",
    "                R_shift_EC_SR.data[0]['total_reward'], \n",
    "                P_shift_MF_SR.data[0]['total_reward'], \n",
    "                P_shift_EC_SR.data[0]['total_reward']]\n",
    "\n",
    "plot_train_test(training.data[0]['total_reward'], test_data_SR, labels=['R - MF', 'R - EC', 'P - MF', 'P - EC' ], smooth=True, savetitle='SR') # arch B w SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = e2.DataFilter(df, expt_type=[14], load_from=['59b3078f-d50e-4011-93e4-f18d65133ac1'])\n",
    "print(len(P_shift_MF.data), len(x.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_id = '7e0a8d56-01b7-4168-9d6c-eae17873cc0e'\n",
    "anim = single_record(save_id)\n",
    "load_env_id = (df.loc[df['save_id']== save_id]['load_from']).item()\n",
    "reward_info = (df.loc[df['save_id']== save_id]['rewards']).item().strip('{}')\n",
    "reward_loc = eval(reward_info.split(':')[0])\n",
    "reward_mag = float(reward_info.split(':')[1])\n",
    "\n",
    "\n",
    "env = pickle.load(open(parent_dir + f'environments/{load_env_id}_env.p', 'rb'))\n",
    "env.rewards = {reward_loc:reward_mag}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.colorbar as colorbar\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.animation as animation\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "def make_arrows(action, probability):\n",
    "    if probability == 0:\n",
    "        dx, dy = 0, 0\n",
    "        head_w, head_l = 0, 0\n",
    "    else:\n",
    "        dxdy = [(0.0, 0.25),  # D\n",
    "                (0.0, -0.25),  # U\n",
    "                (0.25, 0.0),  # R\n",
    "                (-0.25, 0.0),  # L\n",
    "                (0.1, -0.1),  # points right and up #J\n",
    "                (-0.1, 0.1),  # points left and down # P\n",
    "                ]\n",
    "        dx, dy = dxdy[action]\n",
    "\n",
    "        head_w, head_l = 0.1, 0.1\n",
    "\n",
    "    return dx, dy, head_w, head_l\n",
    "\n",
    "\n",
    "rewards = env.rewards\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "ax1 = fig.add_axes([0, 0, 0.85, 0.85])\n",
    "axc = fig.add_axes([0.85, 0, 0.05, 0.85])\n",
    "\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "cmap = plt.cm.Spectral_r\n",
    "vmax= 2\n",
    "\n",
    "cNorm = colors.Normalize(vmin=0, vmax=vmax)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cmap)\n",
    "cb1 = colorbar.ColorbarBase(axc, cmap=cmap, norm=cNorm)\n",
    "\n",
    "\n",
    "\n",
    "def animate_policy(r):\n",
    "    k = r+2000\n",
    "    ax1.set_title(f\"Trial {k} (Total Reward: {anim.data['total_reward'][k]})\")\n",
    "    # make base grid\n",
    "    ax1.patches = []\n",
    "    ax1.pcolor(env.grid, vmin=0, vmax=vmax, cmap='bone')\n",
    "\n",
    "    # add patch for reward location/s (red)\n",
    "    for rwd_loc in rewards:\n",
    "        rwd_r, rwd_c = rwd_loc\n",
    "        ax1.add_patch(plt.Rectangle((rwd_c, rwd_r), width=0.99, height=1, linewidth=1, ec='white', fill=False))\n",
    "\n",
    "    chance_threshold =0.18\n",
    "    \n",
    "    \n",
    "    policy_array = anim.data['pol_tracking'][k]\n",
    "    for i in range(env.r):\n",
    "        for j in range(env.c):\n",
    "            policy = tuple(policy_array[i, j])\n",
    "\n",
    "            dx, dy = 0.0, 0.0\n",
    "            for ind, k in enumerate(policy):\n",
    "                action = ind\n",
    "                prob = k\n",
    "                if prob < 0.01:\n",
    "                    pass\n",
    "                else:\n",
    "                    dx1, dy1, head_w, head_l = make_arrows(action, prob)\n",
    "                    dx += dx1*prob\n",
    "                    dy += dy1*prob\n",
    "            if dx ==0.0 and dy == 0.0:\n",
    "                pass\n",
    "            else:\n",
    "                colorVal1 = scalarMap.to_rgba(entropy(policy))\n",
    "                x,y = j+0.5, i+0.5\n",
    "                arrow = mpatches.FancyArrow(x,y,dx,dy, color=colorVal1, head_width=0.3, head_length=0.3)\n",
    "                ax1.add_patch(arrow)\n",
    "\n",
    "\n",
    "Writer = animation.writers['pillow']\n",
    "writer = Writer(fps=200, metadata=dict(artist='Me'), bitrate=100)\n",
    "ani = animation.FuncAnimation(fig, animate_policy, frames=100, repeat=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial= 1\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "ax = fig.add_axes([0.1,.3, 0.5, 0.5]) #[left,bottom,width,height] \n",
    "ax2 = fig.add_axes([.65,0.6,0.3, 0.15])\n",
    "ax3 = fig.add_axes([0.65,0.3,0.3, 0.15])\n",
    "ax2.set_title('')\n",
    "ax2.set_ylim([0,1])\n",
    "\n",
    "plt.suptitle(f\"Trial {trial}: Total Reward {anim.data['total_reward'][trial]}\")\n",
    "\n",
    "ax.patches = []\n",
    "ax.pcolor(env.grid, vmin=0, vmax=vmax, cmap='bone')\n",
    "ax.add_patch(plt.Rectangle((15,15), width=0.99, height=1, linewidth=1, ec='white', fill=False))\n",
    "ax.set_aspect('equal')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "\n",
    "trajectory = np.vstack(np.vstack(anim.data['sar'][trial])[:,0])\n",
    "rows = trajectory[:,0]\n",
    "cols = trajectory[:,1]\n",
    "dx, dy = [],[]\n",
    "for ind in range(len(rows)-1):\n",
    "    dx.append(rows[ind+1]-rows[ind])\n",
    "    dy.append(cols[ind+1]-cols[ind])\n",
    "\n",
    "dx=np.asarray(dx)*0.25\n",
    "dy=np.asarray(dy)*0.25\n",
    "\n",
    "def animate_trajectory(i):\n",
    "    if i == 0:\n",
    "        ax.patches = []\n",
    "        ax.add_patch(plt.Rectangle((15,15), width=0.99, height=1, linewidth=1, ec='white', fill=False))\n",
    "\n",
    "    ax.set_title(f\"Event {i}\")\n",
    "    \n",
    "    #ax.pcolor(env.grid, vmin=0, vmax=vmax, cmap='bone')\n",
    "    # make base grid\n",
    "    arrow = mpatches.FancyArrow(rows[i]+0.5,cols[i]+0.5,dx[i],dy[i], head_width=0.2, head_length=0.2, color='white',alpha=0.3)\n",
    "    ax.add_patch(arrow) \n",
    "    ax2.cla()\n",
    "    ax2.set_xticks([0,1,2,3])\n",
    "    ax2.set_xticklabels(['Down','Up','Right','Left'])\n",
    "    ax2.set_yticklabels([0,'',1])\n",
    "    ax2.set_ylim([0,1])\n",
    "    ax2.set_title('EC Policy')\n",
    "    ax2.bar(np.arange(4),np.vstack(np.vstack(anim.data['sar'][trial])[:,1])[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax3.cla()\n",
    "    ax3.set_xticks([0,1,2,3])\n",
    "    ax3.set_yticklabels([0,'',1])\n",
    "    ax3.set_ylim([0,1])\n",
    "    ax3.set_title('MF Policy')\n",
    "    ax3.bar(np.arange(4),list(anim.data['pol_tracking'][trial][rows[i],cols[i]]))\n",
    "    ax3.set_xticklabels(['Down','Up','Right','Left'])\n",
    "\n",
    "    \n",
    "Writer = animation.writers['pillow']\n",
    "writer = Writer(fps=20, metadata=dict(artist='Me'), bitrate=100)\n",
    "ani = animation.FuncAnimation(fig, animate_trajectory, frames=len(trajectory), repeat=True, blit=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(anim.data['total_reward']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dat = single_record('59bdc055-56f7-4095-afe6-bc0286f99dff')\n",
    "testing_ec = single_record('0a8db602-9945-4832-b4db-de485a2f82c0')\n",
    "testing_mf = single_record('9e26aadf-780e-49c9-a1dc-d0be3f2f1757')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_w = e2.DataFilter(df,expt_type=[2], load_from=['59bdc055-56f7-4095-afe6-bc0286f99dff'])\n",
    "\n",
    "unfrozen_w = e2.DataFilter(df,expt_type=[5], load_from=['59bdc055-56f7-4095-afe6-bc0286f99dff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = training_dat.data['total_reward']\n",
    "smoothing =1\n",
    "ec =scale_reward_single(testing_ec.data, target=(15,15))\n",
    "mf =scale_reward_single(testing_mf.data, target=(15,15))\n",
    "plot_train_test(running_mean(train,smoothing), \n",
    "                [running_mean(ec, smoothing),\n",
    "                 running_mean(mf, smoothing)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in scaled_r:\n",
    "    plt.plot(running_mean(i,100), alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(e2)\n",
    "# separate tasks:\n",
    "openfield = e2.DataFilter(df, env_type=['None'], rho=[0.0])\n",
    "obstacles = e2.DataFilter(df, env_type=['None'], rho=[0.1])\n",
    "fourrooms = e2.DataFilter(df, env_type=['room'])\n",
    "envs = [openfield, obstacles,fourrooms]\n",
    "env_names = ['openfield', 'obstacles', '4rooms']\n",
    "# plot \n",
    "plot_reward(envs, env_names, expt = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show training by env type\n",
    "fig, ax = plt.subplots(1,3, sharey=True)\n",
    "smoothing = 100 \n",
    "for j, task in enumerate(envs):\n",
    "    title = env_names[j]\n",
    "    A_ = e2.DataFilter(task.info, arch = ['A'])\n",
    "    B_ = e2.DataFilter(task.info, arch = ['B'])\n",
    "\n",
    "    data_collection = [A_, B_]\n",
    "    labels = ['No SR', 'With SR']\n",
    "    \n",
    "    for i, sep in enumerate(data_collection):\n",
    "        dat = sep.get_expt_data(expt_type=0)\n",
    "        for ii, d in enumerate(dat):\n",
    "            if ii == 0:\n",
    "                ax[j].plot(running_mean(d['total_reward'], smoothing), c=colors[i], label=labels[i])\n",
    "            else:\n",
    "                ax[j].plot(running_mean(d['total_reward'], smoothing), c=colors[i])\n",
    "    \n",
    "    ax[2].legend(bbox_to_anchor=(1.05,0.95))\n",
    "    ax[j].set_title(title)    \n",
    "    \n",
    "    \n",
    "    #plot_reward(arch, ['A', 'B'], title=env_names[j], expt=0)\n",
    "    #plot_reward(arch, ['A', 'B'], title=env_names[i], expt=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_expt in [1,2,4,5]:\n",
    "    print(experiment_types[test_expt])\n",
    "    fig, ax = plt.subplots(1,3, sharey=True)\n",
    "    smoothing = 100 \n",
    "    for j, task in enumerate(envs):\n",
    "        title = env_names[j]\n",
    "        A_ = e2.DataFilter(task.info, arch = ['A'])\n",
    "        B_ = e2.DataFilter(task.info, arch = ['B'])\n",
    "\n",
    "        data_collection = [A_, B_]\n",
    "        labels = ['No SR', 'With SR']\n",
    "\n",
    "        for i, sep in enumerate(data_collection):\n",
    "            dat = sep.get_expt_data(expt_type=test_expt)\n",
    "            for ii, d in enumerate(dat):\n",
    "                if ii == 0 and j ==0:\n",
    "                    ax[j].plot(running_mean(d['total_reward'], smoothing), c=colors[i], label=labels[i])\n",
    "                else:\n",
    "                    ax[j].plot(running_mean(d['total_reward'], smoothing), c=colors[i])\n",
    "\n",
    "        fig.legend(loc='lower center', bbox_to_anchor=(0.5,0), ncol=2)\n",
    "        ax[j].set_title(title)  \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = openfield\n",
    "\n",
    "mf_only = e2.DataFilter(task.info,arch=['B'],expt_type=[1,4])\n",
    "with_ec = e2.DataFilter(task.info,arch=['B'], expt_type=[2,5])\n",
    "subtask = with_ec\n",
    "\n",
    "\n",
    "lb = -2.5\n",
    "ub = 125\n",
    "smoothing = 100\n",
    "for i in range(len(subtask.data)):\n",
    "    #print(subtask.info.iloc[i])\n",
    "    tag = f\"Forget:{subtask.info.iloc[i]['use_pvals']} | alpha:{subtask.info.iloc[i]['alpha']} | beta:{subtask.info.iloc[i]['beta']}\"\n",
    "    x = running_mean((1/(ub-lb))*(np.asarray(subtask.data[i]['total_reward']) -lb), smoothing)\n",
    "    plt.plot(x, label=tag)\n",
    "#plt.ylim((0,1))\n",
    "plt.legend(bbox_to_anchor=(1.05,0.95))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = openfield\n",
    "\n",
    "mf_only = e2.DataFilter(task.info, expt_type=[1,4])\n",
    "with_ec = e2.DataFilter(task.info, expt_type=[2,5], beta=['10000'])\n",
    "\n",
    "stuff = [mf_only, with_ec]\n",
    "print(len(mf_only.data))\n",
    "for i in mf_only.data:\n",
    "    \n",
    "    plt.plot(running_mean(i['total_reward'],100))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "for ii, i in enumerate(with_ec.data):\n",
    "    \n",
    "    plt.plot(running_mean(i['total_reward'], 100))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in with_ec.info.columns:\n",
    "    print(j)\n",
    "    for ii in range(len(with_ec.data)):\n",
    "        print(with_ec.info.loc[ii][j])\n",
    "    print('======')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import environment as gw \n",
    "sys.modules['gw'] = gw\n",
    "import pickle\n",
    "filename = './data/results/65d67225-ad1e-4b47-9d48-e3c1bb893028_data.p'\n",
    "chx = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(chx['total_reward'])\n",
    "print(chx['arbitration_count'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = single_record('59bdc055-56f7-4095-afe6-bc0286f99dff')\n",
    "train = single_record('8600f485-3160-4238-a1c7-f070c7ab6c17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a.data['total_reward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_test(train.data['total_reward'], norm_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = e2.DataFilter(df, env_type=['None'], rho=[0.0], expt_type=[0])\n",
    "print(ttt.data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ttt.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = [ttt.data[ind]['total_reward'] for ind in range(len(ttt.data))]\n",
    "datav = running_mean(np.average(sss,axis=0), 30)\n",
    "plt.figure()\n",
    "plt.plot(datav, alpha=1)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plot_train_test(datav, running_mean(a1.data[0]['total_reward'],30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "beta = 10000\n",
    "threshold = 0.01\n",
    "decay = np.power(threshold, 1/beta)\n",
    "\n",
    "#mfcs = decay*old_mfcs + alpha*last_reward\n",
    "weight = 0.01\n",
    "#some_rewards = [np.random.choice([0,1], p=[1-weight, weight]) for _ in range(100)]\n",
    "def plot_decay(alpha,beta):\n",
    "    threshold = 0.01\n",
    "    decay = np.power(threshold, 1/beta)\n",
    "    \n",
    "    number_ = 500 \n",
    "    #r = np.ones(number_)*(-0.5)\n",
    "    #r[0]=alpha\n",
    "    r = [np.random.choice([-0.01,1], p=[1-weight, weight]) for _ in range(number_)]\n",
    "    mfcs = []\n",
    "    mfcs.append(0)\n",
    "    for num in range(number_):\n",
    "        step = r[num]\n",
    "        if step <0:\n",
    "            step = 0 \n",
    "        cs = decay*mfcs[num] + alpha*step\n",
    "        if cs>1:\n",
    "            cs =1\n",
    "        elif cs<0:\n",
    "            cs=0\n",
    "        mfcs.append(cs)\n",
    "    plt.plot(r,'r|')\n",
    "    plt.plot(mfcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decay(0.5,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
