{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import sys \n",
    "sys.path.insert(0,'../rl_network'); import actorcritic as ac\n",
    "sys.path.insert(0,'../environments/'); import gridworld as eu; import stategen as sg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline \n",
    "fig_savedir = '../data/figures/'\n",
    "print_freq = 1/10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (3, 7), (3, 8), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (4, 7), (4, 8), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (5, 7), (5, 8), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (7, 1), (7, 2), (7, 3), (7, 4), (7, 5), (7, 6), (7, 7), (7, 8), (8, 1), (8, 2), (8, 3), (8, 4), (8, 5), (8, 6), (8, 7), (8, 8)] [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (1, 0), (1, 9), (2, 0), (2, 9), (3, 0), (3, 9), (4, 0), (4, 9), (5, 0), (5, 9), (6, 0), (6, 9), (7, 0), (7, 9), (8, 0), (8, 9), (9, 0), (9, 1), (9, 2), (9, 3), (9, 4), (9, 5), (9, 6), (9, 7), (9, 8), (9, 9)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reload(eu)\n",
    "# environment parameters \n",
    "y_height = 8\n",
    "x_width = 8\n",
    "walls = True\n",
    "if not walls:\n",
    "    y_height = y_height+2\n",
    "    x_width = x_width+2\n",
    "rho = 0\n",
    "maze_type = 'none'\n",
    "port_shift = 'none'\n",
    "\n",
    "#make environment\n",
    "maze = eu.gridworld([y_height, x_width], \n",
    "                    rho = rho, \n",
    "                    maze_type = maze_type, \n",
    "                    port_shift = port_shift, \n",
    "                    walls = walls)\n",
    "#maze.rwd_loc = [(int(y_new/2),int(x_new/2))]\n",
    "for i in maze.rwd_loc: \n",
    "    maze.orig_rwd_loc.append(i)\n",
    "\n",
    "\n",
    "\n",
    "state_type = 'conv'\n",
    "\n",
    "if state_type == 'pcs':\n",
    "    # place cell parameters\n",
    "    num_pc = 1000\n",
    "    fwhm = 0.05\n",
    "    pcs = sg.PlaceCells(num_cells=num_pc, grid=maze, fwhm=fwhm)\n",
    "\n",
    "    #show environment\n",
    "    eu.make_env_plots(maze,env=True,pc_map=True,pcs=pcs, save=False)\n",
    "else: \n",
    "    eu.make_env_plots(maze,env=True)\n",
    "\n",
    "## test out gridworld wrapper. \n",
    "env = eu.gymworld(maze)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if state_type == 'conv':\n",
    "    if maze.bound:\n",
    "        input_dims = (y_height+2,x_width+2,3)\n",
    "    else: \n",
    "        input_dims = (y_height, x_width, 3)\n",
    "    hid_types = ['conv', 'pool', 'linear']\n",
    "    hid_dims = [(9,9,3), (8,8,3), 500]\n",
    "\n",
    "elif state_type == 'pcs':\n",
    "    input_dims = 1000\n",
    "    hid_types = ['linear']\n",
    "    hid_dims = [500]\n",
    "    \n",
    "action_dims = len(maze.actionlist)\n",
    "batch_size = 1\n",
    "\n",
    "NUM_EVENTS = 100\n",
    "NUM_TRIALS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ac)\n",
    "MF = ac.AC_Net(input_dims, action_dims, batch_size, hid_types, hid_dims)\n",
    "discount_factor = 0.98\n",
    "\n",
    "eta = 5e-4 #gradient descent learning rate\n",
    "opt = ac.optim.Adam(MF.parameters(), lr = eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "image to non Conv2d(3, 3, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1)) layer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f44a56e5dc8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mMF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreinit_hid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EVENTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpolicy_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mchoice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolicy_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mNUM_EVENTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/annik/Dropbox/LINC Lab Documents/Research/MDP/MEMRL/rl_network/actorcritic.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    183\u001b[0m                         \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'conv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pool'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image to non {} layer'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: image to non Conv2d(3, 3, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1)) layer"
     ]
    }
   ],
   "source": [
    "total_loss = [[],[]]\n",
    "total_reward = []\n",
    "val_maps = []\n",
    "\n",
    "blocktime = time.time()\n",
    "for trial in xrange(NUM_TRIALS):\n",
    "    reward_sum = 0\n",
    "    if state_type == 'pcs':\n",
    "        get_pcs = pcs.activity(env.reset())\n",
    "        state = ac.Variable(ac.torch.FloatTensor(get_pcs))\n",
    "    elif state_type == 'conv':\n",
    "        env.reset()\n",
    "        # because we need to include batch size of 1 \n",
    "        frame = np.expand_dims(sg.get_frame(maze), axis=0)\n",
    "        state = ac.Variable(ac.torch.FloatTensor(frame))\n",
    "        \n",
    "    MF.reinit_hid()\n",
    "    for event in xrange(NUM_EVENTS):\n",
    "        policy_, value_ = MF(state)\n",
    "        choice, policy, value = ac.select_action(MF,policy_, value_)\n",
    "        if event < NUM_EVENTS: \n",
    "            next_state, reward, done, info = env.step(choice)\n",
    "\n",
    "        MF.rewards.append(reward)\n",
    "        if state_type == 'pcs':\n",
    "            state = ac.Variable(ac.torch.FloatTensor(pcs.activity(next_state)))       # update state\n",
    "        elif state_type == 'conv':\n",
    "            # because we need to include batch size of 1 \n",
    "            frame = np.expand_dims(sg.get_frame(maze), axis = 0)\n",
    "            state = ac.Variable(ac.torch.FloatTensor(frame))\n",
    "        reward_sum += reward\n",
    "\n",
    "    p_loss, v_loss = ac.finish_trial(MF, discount_factor,opt)\n",
    "    \n",
    "    total_loss[0].append(p_loss.data[0])\n",
    "    total_loss[1].append(v_loss.data[0])\n",
    "    total_reward.append(reward_sum)\n",
    "    \n",
    "    #value_map = ac.generate_values(maze,MF,pcs)\n",
    "    #val_maps.append(value_map.copy())\n",
    "    \n",
    "    #if trial%10 == 0:\n",
    "    #    eu.save_value_map(value_map.copy(), maze, trial)\n",
    "    \n",
    "    if trial%(print_freq*NUM_TRIALS)==0 or trial == NUM_TRIALS-1: \n",
    "        print \"[{0}]  Trial {1} total reward = {2} (Avg {3:.3f})\".format(time.strftime(\"%H:%M:%S\", time.localtime()), trial, reward_sum, float(reward_sum)/float(NUM_EVENTS)), \"Block took {0:.3f}\".format(time.time()-blocktime)\n",
    "        blocktime = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(total_loss[0], label='p')\n",
    "plt.plot(total_loss[1], label='v')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(total_reward, label='r', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu.print_value_maps(maze,val_maps,maps=698,save_dir=fig_savedir,title='Value Map') ### see individual map with kwarg maps=X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
