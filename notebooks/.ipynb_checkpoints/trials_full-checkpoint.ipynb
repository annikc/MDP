{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from importlib import reload\n",
    "from modules import * \n",
    "import pickle\n",
    "import csv\n",
    "fig_savedir = '../data/figures/'\n",
    "\n",
    "'''\n",
    "to do \n",
    "- in order to test moved reward, need to work on \n",
    "    - recall of memory functions \n",
    "    - cosh function / envelopes\n",
    "    - weighting with similarity score?\n",
    "    - bootstrapping from EC to MF\n",
    "        - function that controls switch from EC to MF? \n",
    "        - also a decay function, how to tune envelope parameter? \n",
    "\n",
    "- genetic algorithms\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(eu)\n",
    "grid_params = {\n",
    "    'y_height':     10, \n",
    "    'x_width':      20,\n",
    "    'walls':        False,\n",
    "    'rho':          0.1,\n",
    "    'maze_type':    'none',\n",
    "    'port_shift':   'none' \n",
    "}\n",
    "\n",
    "#make environment\n",
    "maze = eu.gridworld(grid_params)\n",
    "gp.plot_env(maze)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def reset_agt(agent_params):\n",
    "        ## some stupid reward placement shit -- replace later\n",
    "    if agent_params['load_model'] == True:\n",
    "        if agent_params['rwd_placement'] == 'training_loc':\n",
    "            maze.set_rwd([(int(grid_params['x_width']/2), int(grid_params['y_height']/2))])\n",
    "        if agent_params['rwd_placement'] == 'moved_loc':\n",
    "            maze.set_rwd([(int(3*grid_params['x_width']/4)),int(grid_params['y_height']/4)])\n",
    "    else:\n",
    "        maze.set_rwd([(int(grid_params['x_width']/2),int(grid_params['y_height']/2))])\n",
    "        \n",
    "    # make agent \n",
    "    agent_params = sg.gen_input(maze, agent_params)\n",
    "    MF,opt = ac.make_agent(agent_params, freeze=False)\n",
    "\n",
    "    if agent_params['use_EC']:\n",
    "        #agent_params['cachelim'] = int(0.5*np.prod(maze.grid.shape))\n",
    "        agent_params['EC'] = ec.ep_mem(MF,agent_params['cachelim'])\n",
    "    \n",
    "    run_dict = {}\n",
    "    run_dict = {\n",
    "        'NUM_EVENTS':   300,\n",
    "        'NUM_TRIALS':   30,\n",
    "        'environment':  maze,\n",
    "        'agent':        MF,\n",
    "        'optimizer':    opt,\n",
    "        'agt_param':    agent_params\n",
    "    }\n",
    "    \n",
    "    return run_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_params = {\n",
    "        'load_model':   False,\n",
    "        'load_dir':     '../data/outputs/gridworld/openfield{}{}.pt'.format(grid_params['x_width'],grid_params['y_height']),\n",
    "        'rwd_placement':'training_loc',\n",
    "        'action_dims':  len(maze.actionlist),\n",
    "        'lin_dims':     500,\n",
    "        'batch_size':   1,\n",
    "        'gamma':        0.98, #discount factor\n",
    "        'eta':          5e-4,\n",
    "        'temperature':  1,\n",
    "        'use_EC':       True,\n",
    "        'cachelim':     300, # memory limit should be ~75% of #actions x #states\n",
    "        'state_type':   'conv'\n",
    "    }\n",
    "run_dict = reset_agt(agent_params)\n",
    "reload(gp)\n",
    "gp.plot_env(maze)\n",
    "\n",
    "print(maze.rwd_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(expt)\n",
    "run_dict = reset_agt(agent_params)\n",
    "#expt.run_full_trials(run_dict, pen = -0.0)\n",
    "expt.run_truncated_trials(run_dict, pen=-0.01, use_EC=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_loss = run_dict['total_loss'][0]\n",
    "print(len(policy_loss))\n",
    "value_loss = run_dict['total_loss'][1]\n",
    "tot_reward = run_dict['total_reward']\n",
    "trial_length = run_dict['trial_length']\n",
    "pick = [tot_reward, policy_loss, value_loss, trial_length]\n",
    "pickle.dump(pick, open(\"pickles/initial_training.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac.torch.save(run_dict['agent'],agent_params['load_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv, pp = ac.snapshot(agent=run_dict['agent'], maze =run_dict['environment'])\n",
    "\n",
    "gp.plot_polmap(run_dict['environment'], pp)\n",
    "gp.plot_valmap(run_dict['environment'], vv, p_range = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = ac.mem_snapshot(run_dict['environment'], agent_params['EC'], trial_timestamp=1, decay=100)\n",
    "gp.plot_polmap(run_dict['environment'],ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_ = 0 \n",
    "for k, v in agent_params['EC'].cache_list.items():\n",
    "    if v[2] == (10,10):\n",
    "        key_ = k\n",
    "        print(agent_params['EC'].cache_list[key_][0])\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(np.arange(6), agent_params['EC'].recall_mem(key_, 26))\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,1, sharex=True)\n",
    "ax[0].plot(policy_loss)\n",
    "ax[0].axvline(x = run_dict['NUM_TRIALS'],color='k', linestyle=':', alpha=0.5)\n",
    "ax[0].set_ylabel('Policy Loss')\n",
    "ax[1].plot(value_loss)\n",
    "ax[1].axvline(x = run_dict['NUM_TRIALS'],color='k', linestyle=':', alpha=0.5)\n",
    "ax[1].set_ylabel('Value Loss')\n",
    "\n",
    "#ax[0].arrow(2000, max(policy_loss), 0, -600, head_width=50, head_length=100, fc='k', ec='k')\n",
    "#ax[1].arrow(2000, max(value_loss), 0, -600, head_width=50, head_length=100, fc='k', ec='k')\n",
    "\n",
    "#plt.savefig('../data/figures/loss_after_trunc_training.svg', format='svg')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = -1\n",
    "print(value_loss[x])\n",
    "print(policy_loss[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv, pp = ac.snapshot(agent=run_dict['agent'], maze =run_dict['environment'])\n",
    "reload(gp)\n",
    "gp.plot_polmap(run_dict['environment'], pp)\n",
    "gp.plot_valmap(run_dict['environment'], vv, p_range=[0,1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pvals(p, **kwargs):\n",
    "    envelope = kwargs.get('envelope', 50)\n",
    "    mfc      = kwargs.get('conf_score', 1)\n",
    "    return mfc*np.round(1 / np.cosh(p / envelope), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = np.linspace(1,200, 100)#np.sort(np.random.randint(1,100,10))\n",
    "b = 10*np.arange(10)+5\n",
    "for i in b:\n",
    "    a_p = test_pvals(a, envelope=i)\n",
    "    plt.plot(a, a_p, '-', label=f'{i}')\n",
    "plt.legend(loc=0)\n",
    "#ax[1].plot(a_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EC = agent_params['EC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "meas_time = time.time()\n",
    "x = np.asarray(list(agent_params['EC'].cache_list.keys()))\n",
    "#x = np.asarray([*agent_params['EC'].cache_list.keys()])\n",
    "print(time.time() - meas_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ec)\n",
    "test_case = x[0]+ 0.3*(np.random.randn(500))\n",
    "key, index, sim = EC.cosine_sim(test_case)\n",
    "print(key[0:10], index, sim)\n",
    "EC.recall_mem(key, timestep=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac.torch.save(run_dict['agent'],agent_params['load_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
