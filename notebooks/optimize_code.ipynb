{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from importlib import reload\n",
    "from modules import * \n",
    "fig_savedir = '../data/figures/'\n",
    "\n",
    "grid_params = {\n",
    "    'y_height':   20,\n",
    "    'x_width':    20,\n",
    "    'walls':      False,\n",
    "    'rho':        0,\n",
    "    'maze_type':  'none',\n",
    "    'port_shift': 'none'\n",
    "}\n",
    "\n",
    "\n",
    "agent_params = {\n",
    "    'load_model':   True,\n",
    "    'load_dir':     '../data/outputs/gridworld/MF{}{}training.pt'.format(grid_params['x_width'],grid_params['y_height']),\n",
    "    'action_dims':  6, #=len(maze.actionlist)\n",
    "    'batch_size':   1,\n",
    "    'gamma':        0.98, #discount factor\n",
    "    'eta':          5e-4,\n",
    "    'temperature':  1,\n",
    "    'use_EC':       False,\n",
    "    'cachelim':     100, # memory limit should be ~75% of #actions x #states\n",
    "    'state_type':   'conv'\n",
    "}\n",
    "\n",
    "run_dict = {\n",
    "    'NUM_EVENTS':   150,\n",
    "    'NUM_TRIALS':   5000,\n",
    "    'print_freq':   1/10,\n",
    "    'total_loss':   [[],[]],\n",
    "    'total_reward': [],\n",
    "    'val_maps':     [],\n",
    "    'policies':     [{},{}],\n",
    "    'deltas':       [],\n",
    "    'spots':        [],\n",
    "    'vls':          []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/annik/.local/lib/python3.6/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/annik/.local/lib/python3.6/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/annik/.local/lib/python3.6/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/annik/.local/lib/python3.6/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "#make environment\n",
    "maze = eu.gridworld(grid_params)\n",
    "maze.set_rwd([(int(grid_params['y_height']/2),int(grid_params['x_width']/2))])\n",
    "env = eu.gymworld(maze) # openAI-like wrapper \n",
    "\n",
    "#update agent params dictionary with layer sizes appropriate for environment \n",
    "agent_params = sg.gen_input(maze, agent_params)\n",
    "\n",
    "MF,opt = ac.make_agent(agent_params)\n",
    "\n",
    "agent_params['cachelim'] = int(0.75*np.prod(maze.grid.shape))\n",
    "\n",
    "EC = ec.ep_mem(MF,agent_params['cachelim']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function for runs with episodic mem and without -- take use_EC as a param\n",
    "# assume just for conv inputs \n",
    "def run_trials(run_dict, use_EC, **kwargs):\n",
    "    save_data  = kwargs.get('save', True)\n",
    "    NUM_TRIALS = 2 #run_dict['NUM_TRIALS']\n",
    "    NUM_EVENTS = 50 #run_dict['NUM_EVENTS']\n",
    "    \n",
    "    blocktime = time.time()\n",
    "    \n",
    "    if use_EC:\n",
    "        EC.reset_cache()\n",
    "        add_mem_dict = {} #dictionary of items which get put into memory cache\n",
    "        timestamp    = 0\n",
    "        \n",
    "\n",
    "        for trial in range(NUM_TRIALS):\n",
    "            tt = 0\n",
    "            trialstart_stamp = timestamp\n",
    "\n",
    "            reward_sum   = 0\n",
    "            v_last       = 0\n",
    "\n",
    "            env.reset() \n",
    "\n",
    "            state = ac.Variable(ac.torch.FloatTensor(sg.get_frame(maze)))\n",
    "            MF.reinit_hid() #reinit recurrent hidden layers\n",
    "\n",
    "            for event in range(NUM_EVENTS):\n",
    "                # pass state through EC module\n",
    "                policy_, value_, lin_act_ = MF(state)\n",
    "                add_mem_dict['state'] = maze.cur_state\n",
    "\n",
    "                choice, policy, value = ac.select_action(MF,policy_, value_)\n",
    "                if event < NUM_EVENTS: \n",
    "                    next_state, reward, done, info = env.step(choice)\n",
    "\n",
    "                MF.rewards.append(reward)\n",
    "\n",
    "                delta = reward + agent_params['gamma']*value - v_last  #compute eligibility trace/rpe approximation\n",
    "\n",
    "                add_mem_dict['activity']  = tuple(lin_act_.view(-1).data)\n",
    "                add_mem_dict['action']    = choice\n",
    "                add_mem_dict['delta']     = delta\n",
    "                add_mem_dict['timestamp'] = timestamp            \n",
    "                \n",
    "                st = time.time()\n",
    "                EC.add_mem(add_mem_dict)#add event to memory cache\n",
    "                tx = time.time()-st\n",
    "                tt += tx\n",
    "                #print(tx)\n",
    "                \n",
    "                # because we need to include batch size of 1 \n",
    "                state = ac.Variable(ac.torch.FloatTensor(sg.get_frame(maze)))\n",
    "                reward_sum += reward\n",
    "\n",
    "                v_last = value\n",
    "                timestamp += 1\n",
    "\n",
    "            p_loss, v_loss = ac.finish_trial(MF,agent_params['gamma'],opt)\n",
    "            #print(tt)\n",
    "\n",
    "            if save_data:\n",
    "                #value_map = ac.generate_values(maze,MF)\n",
    "                run_dict['total_loss'][0].append(p_loss.data[0])\n",
    "                run_dict['total_loss'][1].append(v_loss.data[0])\n",
    "                run_dict['total_reward'].append(reward_sum)\n",
    "                #run_dict['val_maps'].append(value_map.copy())\n",
    "                #run_dict['deltas'].append(track_deltas)\n",
    "                #run_dict['spots'].append(track_spots)\n",
    "                #run_dict['vls'].append(visited_locs)\n",
    "\n",
    "            if trial ==0 or trial%100==0 or trial == NUM_TRIALS-1:\n",
    "                print(\"[{0}]  Trial {1} TotRew = {2} ({3:.3f}s)\".format(time.strftime(\"%H:%M:%S\", time.localtime()), trial+1, reward_sum,time.time()-blocktime)) #print(\"[{0}]  Trial {1} total reward = {2} (Avg {3:.3f})\".format(time.strftime(\"%H:%M:%S\", time.localtime()), trial, reward_sum, float(reward_sum)/float(NUM_EVENTS)), \"Block took {0:.3f}\".format(time.time()-blocktime)) \n",
    "                blocktime = time.time()\n",
    "\n",
    "\n",
    "    else:\n",
    "        for trial in range(NUM_TRIALS):\n",
    "            reward_sum   = 0\n",
    "            v_last       = 0\n",
    "            track_deltas = []\n",
    "            track_spots  = []\n",
    "            visited_locs = []\n",
    "\n",
    "            env.reset() \n",
    "            state = ac.Variable(ac.torch.FloatTensor(sg.get_frame(maze)))\n",
    "            MF.reinit_hid() #reinit recurrent hidden layers\n",
    "\n",
    "            for event in range(NUM_EVENTS):\n",
    "                policy_, value_ = MF(state, agent_params['temperature'])[0:2]\n",
    "                choice, policy, value = ac.select_action(MF,policy_, value_)\n",
    "\n",
    "                if event < NUM_EVENTS: \n",
    "                    next_state, reward, done, info = env.step(choice)\n",
    "\n",
    "                MF.rewards.append(reward)\n",
    "                delta = reward + agent_params['gamma']*value - v_last  #compute eligibility trace/rpe approximation\n",
    "                state = ac.Variable(ac.torch.FloatTensor(sg.get_frame(maze)))\n",
    "\n",
    "                reward_sum += reward\n",
    "                v_last = value\n",
    "\n",
    "            p_loss, v_loss = ac.finish_trial(MF,agent_params['gamma'],opt)\n",
    "\n",
    "            if save_data:\n",
    "                #value_map = ac.generate_values(maze,MF)\n",
    "                run_dict['total_loss'][0].append(p_loss.data[0])\n",
    "                run_dict['total_loss'][1].append(v_loss.data[0])\n",
    "                run_dict['total_reward'].append(reward_sum)\n",
    "                #run_dict['val_maps'].append(value_map.copy())\n",
    "                #run_dict['deltas'].append(track_deltas)\n",
    "                #run_dict['spots'].append(track_spots)\n",
    "                #run_dict['vls'].append(visited_locs)\n",
    "\n",
    "            if trial ==0 or trial%10==0 or trial == NUM_TRIALS-1:\n",
    "                print(\"[{0}]  Trial {1} TotRew = {2} ({3:.3f}s)\".format(time.strftime(\"%H:%M:%S\", time.localtime()), trial+1, reward_sum,time.time()-blocktime)) #print(\"[{0}]  Trial {1} total reward = {2} (Avg {3:.3f})\".format(time.strftime(\"%H:%M:%S\", time.localtime()), trial, reward_sum, float(reward_sum)/float(NUM_EVENTS)), \"Block took {0:.3f}\".format(time.time()-blocktime)) \n",
    "                blocktime = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:00:55]  Trial 1 TotRew = 33 (0.135s)\n",
      "[11:00:55]  Trial 2 TotRew = 36 (0.102s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/annik/.local/lib/python3.6/site-packages/ipykernel_launcher.py:64: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/annik/.local/lib/python3.6/site-packages/ipykernel_launcher.py:65: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    }
   ],
   "source": [
    "a1 = run_trials(run_dict, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAD8CAYAAABdCyJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3X1wVfd95/H3R89CAvSADBgRg3mIjWn8gGyTOnG9jWOTbiYkqduQPoR03Xizcabtbrtbu5lZd53tTLLbTbaZJumwthuSyYS4blqYtg4lTtI4abARiZ+EjcHYLsICC6EHJPR0pe/+cQ9wEVdIcC7IiM9r5o5+53d/53d/hyPdz7m/c+5BEYGZmdm5KprqAZiZ2cXNQWJmZqk4SMzMLBUHiZmZpeIgMTOzVBwkZmaWSkGCRNIaSbsl7ZV0X57nyyV9O3n+KUmLcp67P6nfLenOpG6hpB9I2iWpRdLv57Svk7RN0p7kZ20htsHMzM5N6iCRVAx8GXgfsAL4qKQVY5rdDXRGxFLgi8Dnk3VXAOuAa4A1wFeS/jLAH0bECmA1cG9On/cBT0TEMuCJZNnMzKZIIT6R3ATsjYh9ETEEbALWjmmzFtiYlB8D3iNJSf2miBiMiFeBvcBNEdEWET8DiIijwIvAgjx9bQQ+WIBtMDOzc1RSgD4WAPtzlluBm8drExEZSd1AfVK/fcy6C3JXTKbBrgeeSqrmRkRbUj4IzM03KEn3APcAVFVVrbrqqqvOZpvMzC55O3fuPBwRDRO1K0SQnDeSqoG/Bf4gInrGPh8RISnvPV4iYgOwAaCpqSmam5vP61jNzKYbSa9Ppl0hprYOAAtzlhuTurxtJJUAs4GOM60rqZRsiHwzIr6T0+aQpPlJm/nAmwXYBjMzO0eFCJIdwDJJiyWVkT15vmVMmy3A+qR8F/D9yN4tcguwLrmqazGwDHg6OX/yMPBiRHzhDH2tBzYXYBvMzOwcpZ7aSs55fBrYChQDj0REi6QHgeaI2EI2FL4haS9whGzYkLR7FNhF9kqteyNiRNK7gN8Gnpf0TPJSfxIR/wR8DnhU0t3A68Cvp90GMzM7d7oUbiPvcyRmZmdP0s6IaJqonb/ZbmZmqThIzMwsFQeJmZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSoOEjMzS8VBYmZmqThIzMwsFQeJmZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSoOEjMzS8VBYmZmqThIzMwslYIEiaQ1knZL2ivpvjzPl0v6dvL8U5IW5Tx3f1K/W9KdOfWPSHpT0gtj+vpTSQckPZM8fqUQ22BmZucmdZBIKga+DLwPWAF8VNKKMc3uBjojYinwReDzyborgHXANcAa4CtJfwBfS+ry+WJEXJc8/intNpiZ2bkrxCeSm4C9EbEvIoaATcDaMW3WAhuT8mPAeyQpqd8UEYMR8SqwN+mPiPgRcKQA4zMzs/OoEEGyANifs9ya1OVtExEZoBuon+S6+Xxa0nPJ9FftuQ7czMzSuxhPtn8VWAJcB7QB/ydfI0n3SGqW1Nze3n4hx2dmdkkpRJAcABbmLDcmdXnbSCoBZgMdk1z3FBFxKCJGImIU+H8kU2F52m2IiKaIaGpoaDiLzTEzs7NRiCDZASyTtFhSGdmT51vGtNkCrE/KdwHfj4hI6tclV3UtBpYBT5/pxSTNz1n8EPDCeG3NzOz8K0nbQURkJH0a2AoUA49ERIukB4HmiNgCPAx8Q9JesifQ1yXrtkh6FNgFZIB7I2IEQNK3gNuAOZJagQci4mHgf0m6DgjgNeA/pt0GMzM7d8p+MJjempqaorm5eaqHYWZ2UZG0MyKaJmp3MZ5sNzOztxAHiZmZpeIgMTOzVBwkZmaWioPEzMxScZCYmVkqDhIzM0vFQWJmZqk4SMzMLBUHiZmZpeIgMTOzVBwkZmaWioPEzMxScZCYmVkqDhIzM0vFQWJmZqk4SMzMLBUHiZmZpeIgMTOzVAoSJJLWSNotaa+k+/I8Xy7p28nzT0lalPPc/Un9bkl35tQ/IulNSS+M6atO0jZJe5KftYXYBjMzOzepg0RSMfBl4H3ACuCjklaMaXY30BkRS4EvAp9P1l0BrAOuAdYAX0n6A/haUjfWfcATEbEMeCJZNjOzKVKITyQ3AXsjYl9EDAGbgLVj2qwFNiblx4D3SFJSvykiBiPiVWBv0h8R8SPgSJ7Xy+1rI/DBAmyDmZmdo0IEyQJgf85ya1KXt01EZIBuoH6S6441NyLakvJBYG6+RpLukdQsqbm9vX0y22FmZufgoj7ZHhEBxDjPbYiIpohoamhouMAjMzO7dBQiSA4AC3OWG5O6vG0klQCzgY5JrjvWIUnzk77mA2+e88jNzCy1QgTJDmCZpMWSysiePN8yps0WYH1Svgv4fvJpYguwLrmqazGwDHh6gtfL7Ws9sLkA22BmZucodZAk5zw+DWwFXgQejYgWSQ9K+kDS7GGgXtJe4L+QXGkVES3Ao8Au4LvAvRExAiDpW8BPgbdLapV0d9LX54D3StoD3J4sm5nZFFH2g8H01tTUFM3NzVM9DDOzi4qknRHRNFG7i/pku5mZTT0HiZmZpeIgMTOzVBwkZmaWioPEzMxScZCYmVkqDhIzM0vFQWJmZqk4SMzMLBUHiZmZpeIgMTOzVBwkZmaWioPEzMxScZCYmVkqDhIzM0vFQWJmZqk4SMzMLBUHiZmZpVKQIJG0RtJuSXsl3Zfn+XJJ306ef0rSopzn7k/qd0u6c6I+JX1N0quSnkke1xViG8zM7NyUpO1AUjHwZeC9QCuwQ9KWiNiV0+xuoDMilkpaB3we+IikFcA64BrgcuB7kpYn65ypz/8aEY+lHbuZmaVXiE8kNwF7I2JfRAwBm4C1Y9qsBTYm5ceA90hSUr8pIgYj4lVgb9LfZPo0M7O3gEIEyQJgf85ya1KXt01EZIBuoP4M607U559Jek7SFyWV5xuUpHskNUtqbm9vP/utMjOzSbkYT7bfD1wF3AjUAX+cr1FEbIiIpohoamhouJDjMzO7pBQiSA4AC3OWG5O6vG0klQCzgY4zrDtunxHRFlmDwF+TnQYzM7MpUogg2QEsk7RYUhnZk+dbxrTZAqxPyncB34+ISOrXJVd1LQaWAU+fqU9J85OfAj4IvFCAbTAzs3OU+qqtiMhI+jSwFSgGHomIFkkPAs0RsQV4GPiGpL3AEbLBQNLuUWAXkAHujYgRgHx9Ji/5TUkNgIBngE+m3QYzMzt3yn4wmN6ampqiubl5qodhZnZRkbQzIpomancxnmw3M7O3EAeJmZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSqpv0diF5/W7lZ2vLGD9r52GqoauPHyG2mc3TjVwzKzi5Q/kVxiWrtb2bx7M8eGjzG3ei7Hho+xefdmWrtbp3poZnaR8ieSSSjoEXxrK+zYAe3t0NAAN94IjRfu08CON3ZQc2yEWS+2QHc3s2bPhivmseONHf5UMgVyf7ckIcRojJ5Szv2de6t9mkw7nrfa9ti5cZBMoLW7lc1PbaSmtZ25R4fonVnG18r/mXnHYLT3KKqeiRYvZrSmZtw3ghPlIx3omWfRjEpGK8ppeGWQG7f+DY2Lr4Xlyy9IqLS3vszc5/bBzGqoqYGBAap3tnDoHf1wdeFfb7w3Sr9pnPq7VdzVwZPDewmJlZpPy+gbhMStJUvZzyCPZ75AfcygQ8dYWbqAK4rqeH2kg8czX2BJ0RzqiquRkt83dEHKhzNH2Td6+OR4Kgd5fObfsKTxWpbPWU7jsVJan3+S9s4Dp/6ddHWhV1/lcPdB9pX1snL5u7li0bX0DvWyefdm1r597SX9e3Ex8i1SJvB3P36IY9ufZNasOVBRweG2V/mXtn+lZu4V/ELDL/Dkm08TnV2snLmElvKu094ITikfHKWlvJuoq+PWsuX0vbabF0q7WFJ2GXUz56I33mD0sgZ02dzJh9NZlnf+5G8oH4Fra65iTsksAHr6OphRMZMPffzzhfxnPzGNVlNRw8DwAE++9F3i8GFuHVlIRU0dXY0NrL15/SX7ppH7u/XToy8y2Po6RPBafTGLjoxCBIP1NWQ6OyiK4GBtGfM6hxgtgmW1y9lzZA9FEai2nr6uN4kiWDn7Klo6X7og5erZlxFHOrLjWXAtewbaKOrsYPasucyvmstPju7ilvrrqaqYdfLvpGwBLUOtRG0t1TPriaM9jHZ2cnPNCqiq4tnhAwzEEKtKrzgRXA21C7hx9V00XnXjVO+yS85kb5HiIJnAhoc+ydyRGRTNqALgpy9/j/6BYwxVlDC7dh6DbfsB8VpxD4sGZ5z2RnBKubSXRSVzIJNhsGiUTEkRRUUlqPcofaUiECtLL6elqm/y4XS25deP0VI3Qsyaxa31q+jrOcwLh3expBPqlv5CQY9Ydw6+TnlRCdeWLWRPz2sMdndA/RzKa+pZ1lPGs+3PMTC7ilXVyy/40fRp5TxHzKO9R8dvU4BQ/+GPv87CmM3y2VfSvO9JakdKCeAnQ/t4V9mVBLBz4HWuqVhABSUn6vvJ8NqxNhbNmE8FJSfaACfqL0R510ArqyoWZccz2smikWoqKKWrIpg9XEzXYDc1C5cBnPw7GW5nUWkDEOyaNcSq7kr6NcqgMmQyGSqjiMM1lRR3dxNFcGvju6momEFXbwdr3/9HMH/+W3YqbDpO0002SDy1NYGGPtE7K5iVLHcP9VJeUcHsgRG6O9uoLa0kikvo6P03rq68jAA6uvdxdeWVp5eH2rlapURpKS3HXuGa8iVUZGCnjnJNyQIoLmH7wCssGqoBKtl+7CUWdWbDaXv90ROBlKbcOaOCX+qt5dmBw/yg/8fMONrPytE6qsrLeHL/vxb0iDVmz6ayo5+nivfTXwoLVU10dLE/08ORnn4qVUpf3xF+0lnY1z3r8vwbaGl/mXj5iVOOmFeWX0HLgZ+d3qZAAT/7jXa6q4/yVKaXkqEh+stLIaD+WNA/AwjQ8CCV1RX0R+ZEfUVU0EEfV5dk64+3ieBE/YUox/AQ/dXJePo7ubqygf5imD0wTHfRADUVs+nuPAjEyb+T4de4unIxkckQnW/SX1FFRfEMWnp2c03VFQAc6zwZVq8cfpllDVex5/Bu7nvko8yYM/8tM7V3xmm+3LHNnnfeZhjOVL6QYeYgmcCN825g8+GfQFUR1UWVlJZV0DHYw23lS9kzcJD+SiAzQH2mjP4STnsjOKWsSvqH+6G4BBFU9g/TTwaVFFFZUkFkMnREP1eXzZ98OJ1luWukjzmj5fy74Ua+++ZLvKt0CbNGS/hpeTv1JTUAbO/4+Yk/5DTl1zraaJgxnyqg/Wgr/bW1kMnQl9RTXMKxrjYWzVxY0Nc963L7ThaNVAOVbO/bnT1i7hxge/FOFlXUnt6mQAE/WFbGyNAQRYcOEUWiY6SXCFidmUtLUr4yajiS6WUU+MXMPPaM9NMfoo4ZJ+qXRC39mQEA6qm6YOWlo7X0HR9PppQjJcOMZkZYWd7IHh2ha7iPmoESQCf/To6vX1zC0p4i+qqD/kwvKIiSYo4xTHX/CJWzsmG1v6+NI61dVBaXczh6ubLtELuKDjGcTO2VRPBvtRlenIKpvbHTfCVHOk4f27wSXmw/UNADkMmUby1ZyrGaOjY37rog08e+/HcCjbe8j7WZpcwYGOHQ8BGuqb6S5b1llM2uZ0npZXQMdnM4c5TV5VfSMdLL4ZFeVmfm5i+XL6HjslkcVj9XUscR+umrm8mS0nn09/cyMNyfDZsSGBg5GU4DxUkgFaA8e7QMlr+d3hklxLE+qmfMhuVvp1tDVJZUUFGcPdotRLmqP0NfSTBaXMyMkaLsv0PJEFX9GaKkmL6RAapHSwr+umddHuyksrSSiorqbH1lNRWllXQMdeZvM9iVbTNjJh3dB8+5HBI3D81hFuV0a5hbumbx7u5ZzF501YnywnlXkRk4xoqeMpYuamJFdzmZgWO8vf5k/fXzVtEx0MXhoS5W119/wcrXX77q5HgqFpAZGGBFfzV185Ywr34xHSM9zGPmqX8nc26gI3OUw4NdXD86lxW9M8hkBmmomMNoZpibBy9jQVEN/ZkBBkYG6BsdoKq0kqKiIjQS1FXWUlU+k389/DOqKqqprazlla5Xqa+oYU5ZDds7fj4l5X2d+8YZ2yvUdw4wJzkAqT/Yw5w3utg+8PJ5Lb8SHczKFFPz3MvseP675/190p9IJtLYSOOvfpzG45fsLm+g9Z2l7Nj3JH2DR7nl8Bw0fwGjFeXc8vIeBIwuupxbDrxxenn5Qm4pLkV1/Ry+6gr29b3Oyu5Kqoa7eHLoOaK2ltW9V9IyeJCIUVaXX0nLSM9pR6lpyreWX0FPVQldC+pp4gZ6F85lVtUsZpdVF/yItbGolmVDc3hW7VTNrGNVXz0qEjtLexntH+Dm4Tr2VJVMydH0KeXjnybHHDHXD5fmbzOZT5+TKM8eLmPOsusoO7CPmzt6+FDTb4EEo6PQoBPl1vpOdgy/zqGRHhYub+LDZYtpLKqhdU62vn2kh1uqfvHEdMst1RemPBKjJ8fTNUrra8+xY2klhyozLBy+jD+qvpPW2mLae9pO/p3MqeeW0ir0xhuMXF7Fwp4RPrzwozBjBptf+FvKRvpYsuAdPHkkO6VYVVRBxCjHRgZZEjX0l7x1pvbGnebLHdvRPipnnL8ZhnFnHroOwmU3UB31HHqpGd71u+f09jdZDpLJaGw85bLcRqDx1vdnF3K/F3Ldu/O+EZxaPvndkdyTc7d03Zw9wTt6kFsOZyYfTmdZHlk+hxkDI/xSZimsuYvNT38DgCX1y3ny335MFMHq+utPfGRPU7618QbKDhxkWXEZa1f+Bo2D5fDCC6ypX8nm/mcpW/A2lpSq4K971uXyxbQMdmXDe84NtPS8TGSUDfKB9tPbFCjgc0P9l679AHzkE/l//ZLHZOunSmNr68kDrrkN8P4bufH4303u38nyBvjN5FL3nPq1Kz7EjuHX6csJxp1vNDMawc2Nq+HNQzw1sv8tM7U37jRf7tgGquifRUEPQCZ1kDKQvYiqtyxo6FFhd3QevmrrrSj3j045IVSocm6YvbSDHdsfy17rfx5ORjYUz+TG5Aj6Qr7uWZV7j6LD7SeOmHW44+Sl2DOqTm9TUY6OB/yCy9HxwD7b8vJlNJTXcePgHBp/9eMX9IupF4vWl3aw+R/+nJrqeqqHi3h991O8UNZFfW0jHZ2trByqoWreohOfYKbqHMmttTfQ1/ba6WMrq+bJ0jYiRlk5Wk9LefYAZOVhaGngvJVvLbqCiqVX09XXwdo5t9A4zkHKRC7o5b+S1gB/Qfb/V38oIj435vly4OvAKqAD+EhEvJY8dz9wNzAC/F5EbD1Tn5IWA5uAemAn8NsRMXSm8V10QWIX3mTuOHA+An4K7m5wsck96Mg9MGkdOTm1N+UHI2MOmk6Mraet8AcgF/Ag5YIFiaRi4GXgvUArsAP4aETsymnzKeAdEfFJSeuAD0XERyStAL4F3ARcDnwPWJ6slrdPSY8C34mITZL+Cng2Ir56pjE6SMxsypzvGYbzeJByIb9HchOwNyL2JS+8CVgL7Mppsxb406T8GPCXkpTUb4qIQeBVSXuT/sjXp6QXgV8GfiNpszHp94xBYmY2ZcacY52OCnH57wJgf85ya1KXt01EZIBuslNT4607Xn090JX0Md5rASDpHknNkprb29vPYbPMzGwypu33SCJiQ0Q0RURTQ0PDVA/HzGzaKkSQHAAW5iw3JnV520gqAWaTPek+3rrj1XcANUkf472WmZldQIUIkh3AMkmLJZUB64AtY9psAdYn5buA70f2LP8WYJ2k8uRqrGXA0+P1mazzg6QPkj43F2AbzMzsHKU+2R4RGUmfBraSvVT3kYhokfQg0BwRW4CHgW8kJ9OPkA0GknaPkj0xnwHujYgRgHx9Ji/5x8AmSf8T+HnSt5mZTRF/IdHMzPKa7OW/0/Zku5mZXRgOEjMzS8VBYmZmqThIzMwsFQeJmZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSoOEjMzS8VBYmZmqThIzMwsFQeJmZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSoOEjMzSyVVkEiqk7RN0p7kZ+047dYnbfZIWp9Tv0rS85L2SvqSJJ2pX0m3SeqW9Ezy+O9pxm9mZuml/URyH/BERCwDnkiWTyGpDngAuBm4CXggJ3C+CnwCWJY81kyi3ycj4rrk8WDK8ZuZWUppg2QtsDEpbwQ+mKfNncC2iDgSEZ3ANmCNpPnArIjYHhEBfD1n/cn0a2ZmbwFpg2RuRLQl5YPA3DxtFgD7c5Zbk7oFSXls/UT9vlPSs5Iel3TNeAOTdI+kZknN7e3tk98iMzM7KyUTNZD0PWBenqc+k7sQESEpCjWwcfr9GXBFRPRK+hXg78lOieVbbwOwAaCpqang4zIzs6wJgyQibh/vOUmHJM2PiLZkqurNPM0OALflLDcCP0zqG8fUH0jKefuNiJ6ccf2TpK9ImhMRhyfaDjMzOz/STm1tAY5fhbUe2JynzVbgDkm1yUn2O4CtydRVj6TVydVaH8tZP2+/kublXNl1UzL+jpTbYGZmKUz4iWQCnwMelXQ38Drw6wCSmoBPRsTvRsQRSZ8FdiTrPBgRR5Lyp4CvAZXA48lj3H6Bu4D/JCkD9APrkhP1ZmY2RXQpvA83NTVFc3PzVA/DzOyiImlnRDRN1M7fbDczs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmlkqqIJFUJ2mbpD3Jz9px2q1P2uyRtD6nfpWk5yXtlfQlSUrqf01Si6TR5P9/z+3r/qT9bkl3phm/mZmll/YTyX3AExGxDHgiWT6FpDrgAeBm4CbggZzA+SrwCWBZ8liT1L8AfBj40Zi+VgDrgGuStl+RVJxyG8zMLIW0QbIW2JiUNwIfzNPmTmBbRByJiE5gG7BG0nxgVkRsj4gAvn58/Yh4MSJ2j/N6myJiMCJeBfaSDSczM5siaYNkbkS0JeWDwNw8bRYA+3OWW5O6BUl5bP2ZjNfXaSTdI6lZUnN7e/sE3ZqZ2bkqmaiBpO8B8/I89ZnchYgISVGogaUVERuADQBNTU1vmXGZmU03EwZJRNw+3nOSDkmaHxFtyVTVm3maHQBuy1luBH6Y1DeOqT8wwXAOAAvPch0zMzuP0k5tbQGOX4W1Hticp81W4A5JtclJ9juArcmUWI+k1cnVWh8bZ/2xr7dOUrmkxWRP0D+dchvMzCyFtEHyOeC9kvYAtyfLSGqS9BBARBwBPgvsSB4PJnUAnwIeInvS/BXg8WT9D0lqBd4J/KOkrUlfLcCjwC7gu8C9ETGSchvMzCwFZS+Ymt6ampqiubl5qodhZnZRkbQzIpomaudvtpuZWSoOEjMzS8VBYmZmqThIzMwsFQeJmZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSoOEjMzS8VBYmZmqThIzMwsFQeJmZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSoOEjMzSyVVkEiqk7RN0p7kZ+047dYnbfZIWp9Tv0rS85L2SvqSJCX1vyapRdKopKac9osk9Ut6Jnn8VZrxm5lZemk/kdwHPBERy4AnkuVTSKoDHgBuBm4CHsgJnK8CnwCWJY81Sf0LwIeBH+V5zVci4rrk8cmU4zczs5TSBslaYGNS3gh8ME+bO4FtEXEkIjqBbcAaSfOBWRGxPSIC+Prx9SPixYjYnXJsZmZ2AaQNkrkR0ZaUDwJz87RZAOzPWW5N6hYk5bH1E1ks6eeS/kXSu89hzGZmVkAlEzWQ9D1gXp6nPpO7EBEhKQo1sHG0AW+LiA5Jq4C/l3RNRPSMbSjpHuAegLe97W3neVhmZpeuCYMkIm4f7zlJhyTNj4i2ZKrqzTzNDgC35Sw3Aj9M6hvH1B+YYCyDwGBS3inpFWA50Jyn7QZgA0BTU9P5Djgzs0tW2qmtLcDxq7DWA5vztNkK3CGpNjnJfgewNZkS65G0Orla62PjrH+CpAZJxUn5SrIn6Pel3AYzM0shbZB8DnivpD3A7ckykpokPQQQEUeAzwI7kseDSR3Ap4CHgL3AK8DjyfofktQKvBP4R0lbk/a3As9JegZ4DPhkTl9mZjYFlL1ganpramqK5ubTZr/MzOwMJO2MiKaJ2vmb7WZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKqmCRFKdpG2S9iQ/a8dptz5ps0fS+pz6VZKel7RX0pckKan/35JekvScpL+TVJOzzv1J+92S7kwzfjMzSy/tJ5L7gCciYhnwRLJ8Ckl1wAPAzcBNwAM5gfNV4BPAsuSxJqnfBqyMiHcALwP3J32tANYB1yRtvyKpOOU2mJlZCmmDZC2wMSlvBD6Yp82dwLaIOBIRnWRDYo2k+cCsiNgeEQF8/fj6EfHPEZFJ1t8ONOa83qaIGIyIV4G9ZMPJzMymSEnK9edGRFtSPgjMzdNmAbA/Z7k1qVuQlMfWj/UfgG/n9LV9Eusg6R7gnmSxV9Lu8Tdj0uYAhwvQz8XkUttmb+/0d6ltc5rtvWIyjSYMEknfA+bleeozuQsREZJicmObHEmfATLAN8923YjYAGwo8HiaI6KpkH2+1V1q2+ztnf4utW2+ENs7YZBExO3jPSfpkKT5EdGWTFW9mafZAeC2nOVG4IdJfeOY+gM5fX8ceD/wnmTq63hfC8dbx8zMLry050i2AMevwloPbM7TZitwh6Ta5CT7HcDWZEqsR9Lq5Gqtjx1fX9Ia4L8BH4iIY2Neb52kckmLyZ6gfzrlNpiZWQppg+RzwHsl7QFuT5aR1CTpIYCIOAJ8FtiRPB5M6gA+BTxE9qT5K8DjSf1fAjOBbZKekfRXSV8twKMZqoFOAAADkklEQVTALuC7wL0RMZJyG85GQafKLhKX2jZ7e6e/S22bz/v26uSskZmZ2dnzN9vNzCwVB4mZmaXiIJkkSWuS27LslXTaN/gvdpIWSvqBpF2SWiT9flI/qdvgXKwkFUv6uaR/SJYXS3oq2c/fllQ21WMsJEk1kh5LbkH0oqR3Tud9LOk/J7/PL0j6lqSK6baPJT0i6U1JL+TU5d2nyvpSsu3PSbqhEGNwkExCchuWLwPvA1YAH01u1zKdZIA/jIgVwGrg3mQbJ7wNzkXu94EXc5Y/D3wxIpYCncDdUzKq8+cvgO9GxFXAtWS3fVruY0kLgN8DmiJiJVBM9hZL020ff42Tt5c6brx9+j5O3pLqHrK3qUrNQTI5NwF7I2JfRAwBm8jermXaiIi2iPhZUj5K9g1mAZO7Dc5FSVIj8O/JXjlIchn6LwOPJU2m2/bOBm4FHgaIiKGI6GIa72Oy35WrlFQCzADamGb7OCJ+BBwZUz3ePl0LfD2ytgM1yXcAU3GQTM54t3mZliQtAq4HnmJyt8G5WP1fst9XGk2W64GunPu8Tbf9vBhoB/46mc57SFIV03QfR8QB4M+BfyMbIN3ATqb3Pj5uvH16Xt7LHCR2CknVwN8CfxARPbnPJXcYmBbXi0t6P/BmROyc6rFcQCXADcBXI+J6oI8x01jTbB/Xkj0CXwxcDlRx+hTQtHch9qmDZHIuiVuzSColGyLfjIjvJNWHjn/0PcNtcC5GtwAfkPQa2anKXyZ7/qAmmQaB6befW4HWiHgqWX6MbLBM1318O/BqRLRHxDDwHbL7fTrv4+PG26fn5b3MQTI5O4BlydUeZWRP2G2Z4jEVVHJ+4GHgxYj4Qs5Tk7kNzkUnIu6PiMaIWER2f34/In4T+AFwV9Js2mwvQEQcBPZLentS9R6yd4mYlvuY7JTWakkzkt/v49s7bfdxjvH26RbgY8nVW6uB7pwpsHPmb7ZPkqRfITunXgw8EhF/NsVDKihJ7wKeBJ7n5DmDPyF7nuRR4G3A68Cv59ziZlqQdBvwRxHxfklXkv2EUgf8HPitiBicyvEVkqTryF5cUAbsA36H7AHltNzHkv4H8BGyVyX+HPhdsucEps0+lvQtsjfGnQMcIvsfCf49efZpEqh/SXaK7xjwOxHRnHoMDhIzM0vDU1tmZpaKg8TMzFJxkJiZWSoOEjMzS8VBYmZmqThIzMwsFQeJmZml8v8BvYvayyHyySEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cs =['r','g','b','c']\n",
    "plt.figure()\n",
    "for i in range(len(EC.stupid_df)):\n",
    "    xs = np.arange(len(EC.stupid_df[i]))\n",
    "    ys = EC.stupid_df[i]\n",
    "    \n",
    "    plt.scatter(xs, ys, c=cs[i], alpha=0.3)\n",
    "plt.ylim([-0.002,0.002])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(run_dict['total_reward'])\n",
    "plt.ylim([0,run_dict['NUM_EVENTS']])\n",
    " \n",
    "plt.figure(2)\n",
    "plt.plot(run_dict['total_loss'][0], label = 'pol')\n",
    "plt.plot(run_dict['total_loss'][1], label = 'val')\n",
    "plt.legend(loc=0)\n",
    "plt.show()\n",
    "plt.close()\n",
    "#gp.print_value_maps(maze, run_dict['val_maps'], maps=0, val_range=(-1,50), save_dir=fig_savedir, title='Value Map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac.torch.save(MF,agent_params['load_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
