{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nto do \\n- in order to test moved reward, need to work on \\n    - recall of memory functions \\n    - cosh function / envelopes\\n    - weighting with similarity score?\\n    - bootstrapping from EC to MF\\n        - function that controls switch from EC to MF? \\n        - also a decay function, how to tune envelope parameter? \\n\\n- genetic algorithms\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from importlib import reload\n",
    "from modules import * \n",
    "import pickle\n",
    "import csv\n",
    "fig_savedir = '../data/figures/'\n",
    "\n",
    "'''\n",
    "to do \n",
    "- in order to test moved reward, need to work on \n",
    "    - recall of memory functions \n",
    "    - cosh function / envelopes\n",
    "    - weighting with similarity score?\n",
    "    - bootstrapping from EC to MF\n",
    "        - function that controls switch from EC to MF? \n",
    "        - also a decay function, how to tune envelope parameter? \n",
    "\n",
    "- genetic algorithms\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7)\n"
     ]
    }
   ],
   "source": [
    "grid_params = {\n",
    "    'y_height':     10, \n",
    "    'x_width':      10,\n",
    "    'walls':        False,\n",
    "    'rho':          0,\n",
    "    'maze_type':    'none',\n",
    "    'port_shift':   'none' \n",
    "}\n",
    "\n",
    "#make environment\n",
    "maze = eu.gridworld(grid_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def reset_agt(agent_params):\n",
    "        ## some stupid reward placement shit -- replace later\n",
    "    if agent_params['load_model'] == True:\n",
    "        if agent_params['rwd_placement'] == 'training_loc':\n",
    "            maze.set_rwd([(int(grid_params['y_height']/2),int(grid_params['x_width']/2))])\n",
    "        if agent_params['rwd_placement'] == 'moved_loc':\n",
    "            maze.set_rwd([(int(grid_params['y_height']/4),int(3*grid_params['x_width']/4))])\n",
    "        \n",
    "    else:\n",
    "        maze.set_rwd([(int(grid_params['y_height']/2),int(grid_params['x_width']/2))])\n",
    "\n",
    "    # make agent \n",
    "    agent_params = sg.gen_input(maze, agent_params)\n",
    "    MF,opt = ac.make_agent(agent_params, freeze=False)\n",
    "\n",
    "    if agent_params['use_EC']:\n",
    "        #agent_params['cachelim'] = int(0.5*np.prod(maze.grid.shape))\n",
    "        agent_params['EC'] = ec.ep_mem(MF,agent_params['cachelim'])\n",
    "    \n",
    "    run_dict = {}\n",
    "    run_dict = {\n",
    "        'NUM_EVENTS':   300,\n",
    "        'NUM_TRIALS':   2000,\n",
    "        'environment':  maze,\n",
    "        'agent':        MF,\n",
    "        'optimizer':    opt,\n",
    "        'agt_param':    agent_params\n",
    "    }\n",
    "    \n",
    "    return run_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASsAAAEmCAYAAAA6OrZqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADGlJREFUeJzt3X+onYV9x/H3Z0mlje2sxRI6dZg/xCHCZncZtoJz2j/c6uo2hrMwcV1ZBttaVzqK7p/+NegfpbSwzZFZ21LF0kVZnf0ptvsFI1sSBU3SUjGpxkajFG1rYer87o97bG+u5v44z3Pvud+b9wvCPefkPM/zPSR53+d5znluUlVI0kb3c7MeQJJWwlhJasFYSWrBWElqwVhJasFYSWph2VgluS3J8SQPL3jsLUnuS/Ldydcz13ZMSae6lexZfRa4atFjNwH3V9X5wP2T+5K0ZrKSD4UmOQ+4t6oumtz/DnB5VR1L8jbgX6vqgrUcVNKpbdpzVtur6tjk9pPA9pHmkaTXtHXoCqqqkpx09yzJTmDn5O6vDt2epE3hmap662oWmHbP6qnJ4R+Tr8dP9sSq2lVVc1U1N+W2JG0+31vtAtPG6h7ghsntG4AvTbkeSVqRZQ8Dk9wJXA6cleQo8FHgY8AXk7yf+UJeu5ZDStpotgNXA29lfp/nB8DXgcNrtsUVvRs42saWOLclqYPLgD8Dfhc4bdHv/R/zwboF+DKw5D/3fas9NWSsJK3AFuDv+dl7Zcv5F+A64Ccne8KqY+XlNpJW4POsPFQAvw18lVfvfU3PWElaxs3Ae6dY7jLgb0ebwsNASUs4DTjK/In0abwA/CLw1OLf8DBQ0piuZfpQwXzs/mSUSYyVpCX86QjrWM25rpMzVpKWcNEI6zgXOGPwWoyVpCW8aaT1/PzgNRgrSUt4fqT1/HjwGoyVpCU8MsI6ngGeHbwWYyVpCbeOsI7bWObSmxUxVpKW8HnghwOWfxn4h1EmMVaSlvBj4B8HLP/PjPWTGIyVpGXcDHxziuUOAH882hTGStIyXmT+wuR7V7HMfwO/ATw32hTGStIK/AS4Brge+K8lnvcQ8z/v6teBp0edwAuZJU3hV4DfA87iZz8p9KvAf6x0Bau+kHnw/24j6VT04OTX+vEwUFILxkpSC8ZKUgvGSlILxkpSC8ZKUgvGSlILxkpSC8ZKUgvGSlILxkpSC8ZKUgvGSlILxkpSC8ZKUgvGSlILxkpSC8ZKUgvGSlILxkpSC8ZKUgvGSlILxkpSC8ZKUgvGSlILg2KV5ENJDiR5OMmdSV4/1mCStNDUsUpyNvBBYK6qLgK2ANeNNZgkLTT0MHAr8IYkW4FtwPeHjyRJrzZ1rKrqCeDjwGPAMeC5qvrG4ucl2Zlkb5K904+5MR0+fJiqWvNfhw8fnvVLlWYuVTXdgsmZwF3AHwDPAv8E7K6q25dYZrqNbVBVRZJNsx1pHe2rqrnVLDDkMPBdwOGqerqqXgTuBt45YH2SdFJDYvUYcEmSbZn/tn8lcGicsSTpREPOWe0BdgP7gYcm69o10lySdIKpz1lNtTHPWW3o7UjraF3PWUnSujFWklowVpJaMFaSWjBWklowVpJaMFaSWjBWklowVpJaMFaSWjBWklowVpJaMFaSWjBWklowVpJaMFaSWjBWklowVpJaMFaSWjBWklrYOusBOjty5Ajr8R9uHDlyZM23IW10xmqAHTt2zHoE6ZThYaCkFoyVpBaMlaQWjJWkFoyVpBaMlaQWjJWkFoyVpBaMlaQWjJWkFoyVpBaMlaQWjJWkFoyVpBaMlaQWjJWkFoyVpBaMlaQWjJWkFoyVpBaMlaQWBsUqyZuT7E7y7SSHkrxjrMEkaaGh/xXXp4CvVdXvJzkN2DbCTJL0KlPHKskZwGXAHwFU1QvAC+OMJUknGnIYuAN4GvhMkgeS3Jrk9MVPSrIzyd4kewdsS9IpbkistgJvB26pqouB54GbFj+pqnZV1VxVzQ3YlqRT3JBYHQWOVtWeyf3dzMdLkkY3dayq6kng8SQXTB66Ejg4ylSStMjQdwM/ANwxeSfwUeB9w0eSpFcbFKuqehDwXJSkNecn2CW1YKwktWCsJLVgrCS1YKwktWCsJLVgrCS1YKwktWCsJLVgrCS1YKwktWCsJLVgrCS1YKwktWCsJLVgrCS1YKwktWCsJLVgrCS1YKwktWCsJLVgrCS1YKwktWCsJLVgrCS1YKwktWCsJLVgrCS1YKwktWCsJLVgrCS1YKwktWCsJLVgrCS1YKwktWCsJLVgrCS1YKwktWCsJLVgrCS1YKwktWCsJLVgrCS1MDhWSbYkeSDJvWMMJEmvZYw9qxuBQyOsR5JOalCskpwDvBu4dZxxJOm1Dd2z+iTwEeDlkz0hyc4ke5PsHbgtSaewqWOV5GrgeFXtW+p5VbWrquaqam7abUnSkD2rS4H3JDkCfAG4Isnto0wlSYukqoavJLkc+KuqunqZ5w3fmKTNYN9qj7b8nJWkFkbZs1rxxtyzkjTPPStJm5OxktSCsZLUgrGS1IKxktSCsZLUgrGS1IKxktSCsZLUgrGS1IKxktSCsZLUgrGS1IKxktSCsZLUgrGS1IKxktSCsZLUgrGS1IKxktSCsZLUgrGS1IKxktSCsZLUgrGS1IKxktSCsZLUgrGS1IKxktSCsZLUgrGS1IKxktSCsZLUgrGS1IKxktSCsZLUgrGS1IKxktSCsZLUgrGS1IKxktSCsZLUgrGS1MLUsUpybpJvJTmY5ECSG8ccTJIW2jpg2ZeAD1fV/iRvAvYlua+qDo40myT91NR7VlV1rKr2T27/CDgEnD3WYJK00JA9q59Kch5wMbDnNX5vJ7BzjO1IOnWlqoatIHkj8G/A31TV3cs8d9jGJG0W+6pqbjULDHo3MMnrgLuAO5YLlSQNMeTdwACfBg5V1SfGG0mSXm3IntWlwPXAFUkenPz6rZHmkqQTTH2Cvar+E8iIs0jSSfkJdkktGCtJLRgrSS0YK0ktGCtJLRgrSS0YK0ktGCtJLRgrSS0YK0ktGCtJLRgrSS0YK0ktGCtJLRgrSS0YK0ktGCtJLRgrSS0YK0ktGCtJLRgrSS0YK0ktGCtJLRgrSS0YK0ktGCtJLRgrSS0YK0ktGCtJLRgrSS0YK0ktGCtJLRgrSS0YK0ktGCtJLRgrSS0YK0ktGCtJLRgrSS0YK0ktGCtJLRgrSS0MilWSq5J8J8kjSW4aayhJWmzqWCXZAvwd8JvAhcB7k1w41mCStNCQPatfAx6pqker6gXgC8A144wlSScaEquzgccX3D86eUySRrd1rTeQZCewc3L3f4GH13qb6+gs4JlZDzGizfR6NtNrgc33ei5Y7QJDYvUEcO6C++dMHjtBVe0CdgEk2VtVcwO2uaH4ejauzfRaYHO+ntUuM+Qw8H+A85PsSHIacB1wz4D1SdJJTb1nVVUvJfkL4OvAFuC2qjow2mSStMCgc1ZV9RXgK6tYZNeQ7W1Avp6NazO9FvD1kKpai0EkaVRebiOphXWJ1Wa6LCfJuUm+leRgkgNJbpz1TGNIsiXJA0nunfUsQyV5c5LdSb6d5FCSd8x6piGSfGjyd+3hJHcmef2sZ1qNJLclOZ7k4QWPvSXJfUm+O/l65nLrWfNYbcLLcl4CPlxVFwKXAH/e/PW84kbg0KyHGMmngK9V1S8Bv0zj15XkbOCDwFxVXcT8m1nXzXaqVfsscNWix24C7q+q84H7J/eXtB57VpvqspyqOlZV+ye3f8T8P4TWn9xPcg7wbuDWWc8yVJIzgMuATwNU1QtV9exspxpsK/CGJFuBbcD3ZzzPqlTVvwM/WPTwNcDnJrc/B/zOcutZj1ht2stykpwHXAzsme0kg30S+Ajw8qwHGcEO4GngM5PD2luTnD7roaZVVU8AHwceA44Bz1XVN2Y71Si2V9Wxye0nge3LLeAJ9ikleSNwF/CXVfXDWc8zrSRXA8erat+sZxnJVuDtwC1VdTHwPCs4xNioJudyrmE+wr8AnJ7kD2c71bhq/iMJy34sYT1itaLLcjpJ8jrmQ3VHVd0963kGuhR4T5IjzB+iX5Hk9tmONMhR4GhVvbK3u5v5eHX1LuBwVT1dVS8CdwPvnPFMY3gqydsAJl+PL7fAesRqU12WkyTMnw85VFWfmPU8Q1XVzVV1TlWdx/yfzTerqu137qp6Eng8ySsXyl4JHJzhSEM9BlySZNvk796VNH7DYIF7gBsmt28AvrTcAmv+Uxc24WU5lwLXAw8leXDy2F9PPs2vjeEDwB2Tb46PAu+b8TxTq6o9SXYD+5l/J/oBmn2aPcmdwOXAWUmOAh8FPgZ8Mcn7ge8B1y67Hj/BLqkDT7BLasFYSWrBWElqwVhJasFYSWrBWElqwVhJasFYSWrh/wE4Lfpc1tjJKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent_params = {\n",
    "        'load_model':   True,\n",
    "        'load_dir':     '../data/outputs/gridworld/openfield{}{}.pt'.format(grid_params['x_width'],grid_params['y_height']),\n",
    "        'rwd_placement':'moved_loc',\n",
    "        'action_dims':  len(maze.actionlist),\n",
    "        'lin_dims':     500,\n",
    "        'batch_size':   1,\n",
    "        'gamma':        0.98, #discount factor\n",
    "        'eta':          5e-4,\n",
    "        'temperature':  1,\n",
    "        'use_EC':       True,\n",
    "        'cachelim':     300, # memory limit should be ~75% of #actions x #states\n",
    "        'state_type':   'conv'\n",
    "    }\n",
    "run_dict = reset_agt(agent_params)\n",
    "gp.plot_env(maze)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../memory/episodic.py:110: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.round(1 / np.cosh(p / envelope), 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:36:22]  Trial 1 TotRew = -2.9899999999999802 (0.252s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../memory/episodic.py:108: RuntimeWarning: overflow encountered in cosh\n",
      "  return mfc*np.round(1 / np.cosh(p / envelope), 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:37:30]  Trial 11 TotRew = -2.9899999999999802 (68.373s)\n",
      "[16:40:13]  Trial 21 TotRew = -2.9899999999999802 (162.563s)\n",
      "[16:42:35]  Trial 31 TotRew = -2.9899999999999802 (141.730s)\n",
      "[16:44:36]  Trial 41 TotRew = 0.3299999999999996 (121.321s)\n",
      "[16:47:02]  Trial 51 TotRew = -2.9899999999999802 (145.897s)\n",
      "[16:49:48]  Trial 61 TotRew = -2.9899999999999802 (166.000s)\n",
      "[16:52:18]  Trial 71 TotRew = -2.9899999999999802 (150.503s)\n",
      "[16:54:49]  Trial 81 TotRew = -0.7000000000000013 (150.271s)\n",
      "[16:57:15]  Trial 91 TotRew = 0.71 (146.539s)\n",
      "[16:59:02]  Trial 101 TotRew = -2.9899999999999802 (107.272s)\n",
      "[17:01:10]  Trial 111 TotRew = -2.9899999999999802 (127.915s)\n",
      "[17:03:42]  Trial 121 TotRew = -2.9899999999999802 (151.280s)\n",
      "[17:05:55]  Trial 131 TotRew = -2.9899999999999802 (133.170s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e79299bad397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrun_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreset_agt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#expt.run_full_trials(run_dict, pen = -0.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_truncated_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_EC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/LINC Lab Documents/Code/MEMRL/notebooks/experiment.py\u001b[0m in \u001b[0;36mrun_truncated_trials\u001b[0;34m(run_dict, use_EC, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                         \u001b[0mec_pol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall_mem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlin_act\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                         \u001b[0mcandidate_policies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpolicy_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mec_pol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                         \u001b[0mpol_choice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMF_cs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mMF_cs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/LINC Lab Documents/Code/MEMRL/memory/episodic.py\u001b[0m in \u001b[0;36mrecall_mem\u001b[0;34m(self, key, timestep, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;31m# returns the most similar key, as well as the cosine similarity measure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mlin_act\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/LINC Lab Documents/Code/MEMRL/memory/episodic.py\u001b[0m in \u001b[0;36mcosine_sim\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcosine_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;31m# make list of memory keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0mmem_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;31m# compute cosine similarity measure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_dict = reset_agt(agent_params)\n",
    "#expt.run_full_trials(run_dict, pen = -0.0)\n",
    "expt.run_truncated_trials(run_dict, pen=-0.01, use_EC=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(agent_params['EC'].cache_list)):\n",
    "    test_key = list(agent_params['EC'].cache_list.keys())[i]\n",
    "    x = agent_params['EC'].cache_list[test_key][2]\n",
    "    print(\"====\\n\",x)\n",
    "    if x==run_dict['environment'].rwd_loc[0]:\n",
    "        agent_params['EC'].recall_mem(test_key,1, decay=1000, prints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_loss = run_dict['total_loss'][0]\n",
    "value_loss = run_dict['total_loss'][1]\n",
    "tot_reward = run_dict['total_reward']\n",
    "trial_length = run_dict['trial_length']\n",
    "#pick = [tot_reward, policy_loss, value_loss, trial_length]\n",
    "#pickle.dump(pick, open(\"pickles/initial_training.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac.torch.save(run_dict['agent'],agent_params['load_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv, pp = ac.snapshot(agent=run_dict['agent'], maze =run_dict['environment'])\n",
    "\n",
    "gp.plot_polmap(run_dict['environment'], pp)\n",
    "gp.plot_valmap(run_dict['environment'], vv, p_range = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(gp)\n",
    "ttt = ac.mem_snapshot(run_dict['environment'], agent_params['EC'], trial_timestamp=1, decay=1)\n",
    "gp.plot_polmap(run_dict['environment'],ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,1, sharex=True)\n",
    "ax[0].plot(policy_loss)\n",
    "ax[0].axvline(x = run_dict['NUM_TRIALS'],color='k', linestyle=':', alpha=0.5)\n",
    "ax[0].set_ylabel('Policy Loss')\n",
    "ax[1].plot(value_loss)\n",
    "ax[1].axvline(x = run_dict['NUM_TRIALS'],color='k', linestyle=':', alpha=0.5)\n",
    "ax[1].set_ylabel('Value Loss')\n",
    "\n",
    "#ax[0].arrow(2000, max(policy_loss), 0, -600, head_width=50, head_length=100, fc='k', ec='k')\n",
    "#ax[1].arrow(2000, max(value_loss), 0, -600, head_width=50, head_length=100, fc='k', ec='k')\n",
    "\n",
    "#plt.savefig('../data/figures/loss_after_trunc_training.svg', format='svg')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = -1\n",
    "print(value_loss[x])\n",
    "print(policy_loss[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv, pp = ac.snapshot(agent=run_dict['agent'], maze =run_dict['environment'])\n",
    "reload(gp)\n",
    "gp.plot_polmap(run_dict['environment'], pp)\n",
    "gp.plot_valmap(run_dict['environment'], vv, p_range=[0,1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EC = agent_params['EC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "meas_time = time.time()\n",
    "x = np.asarray(list(agent_params['EC'].cache_list.keys()))\n",
    "#x = np.asarray([*agent_params['EC'].cache_list.keys()])\n",
    "print(time.time() - meas_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ec)\n",
    "test_case = x[0]+ 0.3*(np.random.randn(500))\n",
    "key, index, sim = EC.cosine_sim(test_case)\n",
    "print(key[0:10], index, sim)\n",
    "EC.recall_mem(key, timestep=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac.torch.save(run_dict['agent'],agent_params['load_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
