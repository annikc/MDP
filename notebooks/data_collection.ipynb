{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../environments/'); import gw\n",
    "sys.path.insert(0,'../environments/'); import gridworld_plotting as gp\n",
    "sys.path.insert(0,'../rl_network/'); import ac\n",
    "sys.path.insert(0,'../memory/'); import episodic as ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, columns = 10,10\n",
    "env_type = None\n",
    "penalty = -0.01 \n",
    "\n",
    "NUM_TRIALS = 3\n",
    "NUM_EVENTS = 100\n",
    "\n",
    "rerun = False\n",
    "\n",
    "if not rerun:\n",
    "    reward_location = (3,3)\n",
    "    env = gw.GridWorld(rows=rows,cols=columns,\n",
    "                       env_type=env_type,\n",
    "                       rewards = {reward_location:1, (5,7):-10},#rewards={(int(rows/2),int(columns/2)):1},#\n",
    "                       step_penalization=penalty,\n",
    "                       rho=0.0,\n",
    "                       rewarded_action = None)\n",
    "    \n",
    "    agent_params = {\n",
    "        'load_model':  False,\n",
    "        'load_dir':    f'../data/outputs/gridworld/openfield{rows}{columns}.pt',\n",
    "        'freeze_w':    False,\n",
    "\n",
    "        'input_dims':  env.observation.shape,\n",
    "        'action_dims': len(env.action_list),\n",
    "        'hidden_types':['conv','pool','conv', 'pool', 'linear','linear'],\n",
    "        'hidden_dims': [None, None, None, None, 100, 200],\n",
    "\n",
    "        'rfsize':      5,\n",
    "        'stride':      1,\n",
    "        'padding':     1,\n",
    "        'dilation':    1,\n",
    "\n",
    "        'gamma':       0.98,\n",
    "        'eta':         5e-4,\n",
    "\n",
    "        'use_EC':      True,\n",
    "        'EC':          {},\n",
    "        'cachelim':    300,\n",
    "        'mem_temp':    1\n",
    "        }\n",
    "    agent = ac.make_agent(agent_params)\n",
    "    episodic_memory = ec.ep_mem(agent, 300)\n",
    "    data = {'total_reward': [],\n",
    "            'loss': [[],[]],\n",
    "            'trial_length': [],\n",
    "            'trials_run_to_date':0,\n",
    "            'pol_tracking':[],\n",
    "            'val_tracking':[],\n",
    "            'ec_tracking': [],\n",
    "            't': [],\n",
    "            'mfcs':[]\n",
    "           }\n",
    "\n",
    "else:\n",
    "    reward_location = (16,3)\n",
    "    env = gw.GridWorld(rows=rows,cols=columns,\n",
    "                       env_type=env_type,\n",
    "                       rewards = {reward_location:1},#rewards={(int(rows/2),int(columns/2)):1},#\n",
    "                       step_penalization=penalty,\n",
    "                       rho=0.0,\n",
    "                       rewarded_action = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
