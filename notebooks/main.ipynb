{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "sys.path.insert(0,'../rl_network/'); import ac\n",
    "sys.path.insert(0,'../memory/'); import episodic as ec\n",
    "sys.path.insert(0,'../environments/'); import gw; import gridworld_plotting as gp\n",
    "\n",
    "import experiment as expt\n",
    "import torch\n",
    "import uuid\n",
    "import pickle \n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALgAAADECAYAAAAs0+t9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADaZJREFUeJzt3X9snHUdB/D3t931nrv+7kaBljlaaB0ssWQ1Daj8yiSIBEcyYajJEMmAjLgFfwCDEASRiIZE/0BUFpRfyXD7Y1pRotRIGZZFrDBY6VrWZv1x7a49rne9ttdeu49/9JBmuPWe79e5+en7lTQbT5/38/083ZvmBt8+Z0QERFrlneoBiE4mFpxUY8FJNRacVGPBSTUWnFRjwX0wxvzcGPPACT4vxpjz/5czLVj718aYR07w+VM226m0ZAtujLnJGLPPGDNhjIlmf7/FGGOOlxGRO0Tk+xZrfcUY894xx/58nGP3+r0+Hd+SLLgx5tsAfgrgxwDOAnAmgDsAfBZAwXEy+Q5LtgJYbYw5I3utZQAaAISOOXZJ9lxfHGdTbckV3BhTCuBhAFtEZLeIjMu8f4rI10RkOnver40xTxpj/mCMmQBw5bEvA4wx3zXGDBljIsaYbxxvTREZBNAD4LLsobUADgB49ZhjeQD+nr32BcaYvxpjxowxB4wxX1qw7sdm+w/3mdNs2i25gmP+u2QQwG9zOPerAH4AoBjA3oWfMMZ8AcB3AFwFoA7A5xe5Vis+KvNlAF7LXnPhsTdEJGOMCQBoBvAnAJUAvgngBWPMJ0/SbGotxYKvADAqIrMfHjDG/C37nXLKGHPZgnN/KyKvi8hREUkfc50bAfxKRN4VkQkA31tk3YXfrS/FfMFfO+bYq9nfXwygCMAPRWRGRP4C4PcAvnKSZlNrKRY8BmBF9jUvAEBEPiMiZdnPLfya9J/gOlXHfP7wIuu2AviUMaYc8wVuE5FOAGdnj30OH73+rgLQLyJHj7l+9UmaTa2lWPA2ANMA1udw7om2Wg4BWLngnz9xwguJ9ACIALgNQJ+IpBbMcxvmv2O/kT0WAbDSGLPwz+cTAAZPxmyaLbmCi8gYgIcA/MwY82VjTLExJs8YcxGAQh+X+g2ArxtjLjTGhAE8mEPmNQDfyv76ob3ZY2+KyFT22D4AkwDuNsYEjDFXALgOwM6TOJtKS67gACAiP8J8qe4GcCT78QsA9wD4W47X+COAnwD4C4D3s78u5lXM/6Vx4V8KX8se+/d/HhSRGcwX+hoAowB+BmBT9iXNyZpNJcMfeCDNluR3cFo6WHBSjQUn1VhwUm3Z4qd8xPM8KS4utloolUohPz8foVDIKn/06FEkk0mUlZVZ5QFgbGzMKT8+Po6CggIEg0GrfCaTweTkJEpLS61ncL2HZDKJUCiEQCBglU+n08hkMrDtAeB+D6lUCul0elREzlj0ZBHJ+aOhoUFsbd68WXbs2GGdP3z4sFx66aXWeRGRmpoap/yGDRtkz5491vmWlhbZsGGD0wx1dXVO+XXr1snevXut808//bRs2bLFaYbVq1c75W+//XbB/P83WLSzfIlCqrHgpBoLTqqx4KQaC06qseCkGgtOqrHgpBoLTqqx4KQaC06qseCkGgtOqrHgpJqvHzr2PE9WrVpltVA8HkcwGEQ4HLbKz87OIplMoqKiwioPzO+FLikpsc7H43GEQiF4nmeVT6fTmJqaQnl5ufUMrveQSCQQCoVQUPAfnzG6qImJCczOzjrtaU8kEs75I0eO/ENEPr3oybnsqRXuBxcR7gcX4X5wotMKC06qseCkGgtOqrHgpBoLTqqx4KQaC06qseCkGgtOqrHgpBoLTqqx4KQaC06q+doPXlxcLI2NjVYL9fb2IhQK4ayzzrLKz8zMoKenB6tXr7bKA8B7772HCy64wDr//vvvo7y8HMuXL7fKJxIJRKNR1NXVWc/Q2dnp9DXo7u5GZWWl9X7skZERpFIp1NTUWM/geg99fX3o7e3NaT+4r4LX19fL888/bzXUo48+ijVr1mD9+lzef/XjhoeH8cADD+Cpp56yygPADTfcgF27dlnn7733XlxzzTW4/PLLrfJvvvkmdu3ahccee8x6ho0bN+LFF1+0zm/duhW33norGhoarPLNzc3o6OjAPffcYz3DTTfdhJ07c33Lz4975JFH0NzcnFPBfb3DQzgcRlNTk9VQlZWVqK2ttc739fWhtLTUOg8A+fn5TvmKigrU19dbXyOVSmH58uVOMwQCAad8UVERLrzwQutrHDhwAB988IHTDMFg0ClfVVWV87l8DU6qseCkGgtOqrHgpBoLTqqx4KQaC06qseCkGgtOqrHgpBoLTqqx4KQaC06q+dpNGIvF8OSTT1ottH//fiQSCczMzFjl4/E4+vr6rNcHgPHxcad8V1cXmpubEYlErPKdnZ04ePCg0wyJRMIp39/fj927d2P//v1W+ddffx2HDh1ymiEejzvlOzo6cj7XV8HT6TS6urp8DwTMbxUdHR21zo+PjzutDwDLli1zyk9PT2N4eNj6GoODg5iYmHCaIS8vzyk/NzeHgYEB63w0GkUymXSaQUSc8iMjI/4Wy/WDD8DnA/D5AHyi0wgLTqqx4KQaC06qseCkGgtOqrHgpBoLTqqx4KQaC06qseCkGgtOqrHgpBoLTqr5ej6453lSW1trtVA0GoXneSgpKbHKz87OYnR01PoB+sD8D2zYPrwemN+HHA6HUVhYaJWfmppCMpnEmWeeaT2D6z3EYjGEw2GEQiGrfDKZxMzMDFasWGE9w+joqHN+ZGQkp+eDcz+4D9wPzv3gRKcVFpxUY8FJNRacVGPBSTUWnFRjwUk1FpxUY8FJNRacVGPBSTUWnFRjwUk1FpxU87UfPBwOy5o1a6wWGhoagud5KC8vt8pnMhkMDw9j5cqVVnkAGBgYwDnnnGOdj0QiKCoqst7TPjExgUQigaqqKusZBgcHUV1dbZ2PRCIoLS213tM+NjaGdDrttC/f9R6i0Sj6+vpy2g/u6wH45557Lnbu3Gk11P3334+GhgbceOONVvlIJIK77rrLen0AWLdunVP+zjvvxPXXX4+rrrrKKt/W1oYHf/cgLvniJdYzPPfcc9j5S/t7uPnmm7F161Y0NjZa5T98d4iHH37Yeoarr77a6c9h+/bt6Ovry+lcXwUvKCjAeeedZzVUSUkJKisrrfOBQADhcNg6D8y/O4JLvqioCGeffbb1NQ4fPoxgQRAVFRXWM7jeg+d5qK6utr5GZWUlysrKnGYIBAJOeT9fP74GJ9VYcFKNBSfVWHBSjQUn1VhwUo0FJ9VYcFKNBSfVWHBSjQUn1VhwUo0FJ9V87SYcGhrCfffdZ7VQW1sbenp6cOjQIat8IpFAV1eX9foAEI/HnfJvv/02MpkM9u3bZ5Xv6enB0MgQWlparGeYnJp0uofu7m488cQTeOmll6zy7e3tGBgYcJohGo065f18/X0VPD8/H2VlZb4HAoBwOIzS0lLrPAAEg0GnfDgcdsqHQiGUlJRYX6OkpARV71Thuquvs56hZ3cPyr7k9jVw+XMoLi52/jp6nueUz8vz8cIjl4eICx+ALyJ8AL4IH4BPdFphwUk1FpxUY8FJNRacVGPBSTUWnFRjwUk1FpxUY8FJNRacVGPBSTUWnFRjwUk1Xw/AD4VCUldXZ7XQ4OAggsEgVqxYYZXPZDIYGBhATU2NVR6Yf8a468PnCwsLrfcyp1IpxGIxrFq1ynoG13sYGhpCcXExioqKrPLxeBwTExNObyTg+kYEAwMDiMfjOT0An/vBfeB+cO4HJzqtsOCkGgtOqrHgpBoLTqqx4KQaC06qseCkGgtOqrHgpBoLTqqx4KQaC06qseCkmu/94Lb7sePxOILBIMLhsFV+bm4OiUQCFRUVVnkAGBsbc3oudTweh+d5CIVCVvnp6WlMTk6ivLzceob/xj2Ew2EEg0Gr/OTkJDKZDEpLS61ncL2HZDKJwcHBnPaD+3oA/vnnn4+9e/daDbVt2zY0NjZi06ZNVvn+/n5s3rwZL7/8slUeAC666CK0tbVZ5zdt2oSNGzfi2muvtcq3trZix44dePbZZ61naGxsdLqH9evXY/v27bj44out8i+88ALa29vx+OOPW8/Q1NTkdA/btm3DM888k9O5vt/hwfbf3IKCgn+/u4CNRCKBQCDg9J3DGOOUDwQCKCwstL5GYWGh8z3k5eU55ZctW4aioiLra4RCIQSDwVN6D57n5b6W9SpE/wdYcFKNBSfVWHBSjQUn1VhwUo0FJ9VYcFKNBSfVWHBSjQUn1VhwUo0FJ9V87Sbs7+/HLbfcYrVQa2sr2tvbrbfbplIpvPvuu9brA0AsFnPK79u3D9FoFHv27LHKRyIRvPPOO04zHDlyxCl/4MABPPTQQ6iurrbKd3Z2Ynh42GmGSCTilPez1dZXwQsLC3HllVf6HggAent7UVtbiyuuuMIqH4vF8NZbb1mvDwCvvPKKU76jowNr167F2rVrrfOjo6NOM7S0tDjl29vb0dTUhPr6eqt8fn4+PM87pffQ3d2NgwcP5nZyLg8RFz4AX0T4AHwRPgCf6LTCgpNqLDipxoKTaiw4qcaCk2osOKnGgpNqLDipxoKTaiw4qcaCk2osOKnma7vs3NwcYrGY1ULpdBqpVMo6H4/HkclkrPPA/M5Jl/zMzAySyaT1NZLJJKanp51mOHr0qFN+dnYWiUTC+hqpVArpdPqU3kM6nc75XF8PwDfGjAA4bDET0X/bKhE5Y7GTfBWc6P8NX4OTaiw4qcaCk2osOKnGgpNqLDipxoKTaiw4qcaCk2r/AqASKeAGFm11AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set environment parameters\n",
    "rows, columns = 10,10\n",
    "env_type = None\n",
    "penalty = -0.01\n",
    "reward_location = (5,5)\n",
    "rho = 0.0\n",
    "\n",
    "# generate environment object\n",
    "env = gw.GridWorld(rows=rows,cols=columns,env_type=env_type,\n",
    "                   rewards = {reward_location:1},\n",
    "                   step_penalization=penalty,\n",
    "                   rho=rho,\n",
    "                   actionlist = ['Down', 'Up', 'Right', 'Left'],\n",
    "                   rewarded_action=None)\n",
    "\n",
    "# plot environment\n",
    "fig = gw.plotWorld(env, scale=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent - Model Free Actor Critic + Episodic Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent parameters    \n",
    "training = {\n",
    "    'load_model':  False,\n",
    "    'load_dir':    '',\n",
    "    \n",
    "    'architecture': 'A',\n",
    "    'input_dims':  env.observation.shape,\n",
    "    'action_dims': len(env.action_list),\n",
    "    'hidden_types':['conv','pool','conv', 'pool', 'linear','linear'],\n",
    "    'hidden_dims': [None, None, None, None, 100, 200],\n",
    "    \n",
    "    'freeze_w':    False,\n",
    "\n",
    "    'rfsize':      5,\n",
    "\n",
    "    'gamma':       0.98,\n",
    "    'eta':         5e-4,\n",
    "\n",
    "    'use_EC':      False\n",
    "}\n",
    "\n",
    "testing_1 = training.copy()\n",
    "testing_1.update({'load_model':True, 'freeze_w':True})\n",
    "\n",
    "testing_2 = testing_1.copy()\n",
    "testing_2.update({'use_EC':True})\n",
    "\n",
    "testing_4 = testing_1.copy()\n",
    "testing_4.update({'freeze_w':False})\n",
    "\n",
    "testing_5 = testing_4.copy()\n",
    "testing_5.update({'use_EC':True})\n",
    "\n",
    "params = [training, testing_1, testing_2, testing_2, testing_4, testing_5, testing_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment parameters\n",
    "experiment_type = 0\n",
    "\n",
    "NUM_TRIALS = 1000\n",
    "NUM_EVENTS = 100\n",
    "\n",
    "# mixing parameters for MF-EC control\n",
    "alpha = 0.01 # MF confidence boost for reward\n",
    "beta = 100 # MF confidence decay - number of steps to decay to 1% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: -1.0000000000000007 (0.21171975135803223s)\n",
      "100: 1.0199999999999994 (30.660695791244507s)\n",
      "200: -1.0000000000000007 (34.339715003967285s)\n",
      "300: -1.0000000000000007 (32.689512729644775s)\n",
      "400: -1.0000000000000007 (35.5751895904541s)\n",
      "500: -1.0000000000000007 (30.11117148399353s)\n",
      "600: -1.0000000000000007 (31.236591815948486s)\n",
      "700: -1.0000000000000007 (29.549874305725098s)\n",
      "800: -1.0000000000000007 (28.95398259162903s)\n",
      "900: 8.090000000000005 (28.809646606445312s)\n",
      "999: -1.0000000000000007 (28.560487031936646s)\n"
     ]
    }
   ],
   "source": [
    "reload(ec)\n",
    "# create an agent with parameters for a given experiment type\n",
    "agent_params = params[experiment_type]\n",
    "load_weights = False\n",
    "\n",
    "if experiment_type is not 0 and load_weights: \n",
    "    id_key = input('Weights to load: ')\n",
    "    agent_params['load_dir'] = f'../data/outputs/gridworld/weights/{id_key}.pt'\n",
    "\n",
    "# create agent from parameters for given experiment type\n",
    "agent = ac.make_agent(agent_params)\n",
    "\n",
    "# create experiment object\n",
    "ex = expt.test_expt(agent, env, use_mem=agent_params['use_EC'])\n",
    "\n",
    "# run experiment\n",
    "ex.run(NUM_TRIALS, NUM_EVENTS, alpha=alpha,beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: -1.0000000000000007 (0.22663235664367676s)\n",
      "100: 6.070000000000015 (32.90524959564209s)\n",
      "200: 2.030000000000009 (34.73886799812317s)\n",
      "300: 8.090000000000016 (31.51343584060669s)\n",
      "400: 13.140000000000015 (30.41323709487915s)\n",
      "500: -1.0000000000000007 (30.80696988105774s)\n",
      "600: -1.0000000000000007 (36.658408641815186s)\n",
      "700: -1.0000000000000007 (29.84745502471924s)\n",
      "800: -1.0000000000000007 (30.576122522354126s)\n",
      "900: -1.0000000000000007 (31.56575345993042s)\n",
      "999: -1.0000000000000007 (28.305994510650635s)\n"
     ]
    }
   ],
   "source": [
    "ex.run(NUM_TRIALS, NUM_EVENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3e7863f6-b2d4-4907-9017-8d059a4e6eb3 <class 'uuid.UUID'>\n",
      "0 <class 'int'>\n",
      "  <class 'str'>\n",
      "10 <class 'int'>\n",
      "5 <class 'int'>\n",
      "None <class 'str'>\n",
      "(20, 20) <class 'tuple'>\n",
      "0.0 <class 'float'>\n",
      "{(15, 15): 1} <class 'dict'>\n",
      "['Down', 'Up', 'Right', 'Left'] <class 'list'>\n",
      "None <class 'NoneType'>\n",
      "-0.01 <class 'float'>\n",
      "[(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 13), (0, 14), (0, 15), (0, 16), (0, 17), (0, 18), (0, 19), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15), (1, 16), (1, 17), (1, 18), (1, 19), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (2, 10), (2, 11), (2, 12), (2, 13), (2, 14), (2, 15), (2, 16), (2, 17), (2, 18), (2, 19), (3, 0), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (3, 7), (3, 8), (3, 9), (3, 10), (3, 11), (3, 12), (3, 13), (3, 14), (3, 15), (3, 16), (3, 17), (3, 18), (3, 19), (4, 0), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (4, 7), (4, 8), (4, 9), (4, 10), (4, 11), (4, 12), (4, 13), (4, 14), (4, 15), (4, 16), (4, 17), (4, 18), (4, 19), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (5, 7), (5, 8), (5, 9), (5, 10), (5, 11), (5, 12), (5, 13), (5, 14), (5, 15), (5, 16), (5, 17), (5, 18), (5, 19), (6, 0), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (6, 10), (6, 11), (6, 12), (6, 13), (6, 14), (6, 15), (6, 16), (6, 17), (6, 18), (6, 19), (7, 0), (7, 1), (7, 2), (7, 3), (7, 4), (7, 5), (7, 6), (7, 7), (7, 8), (7, 9), (7, 10), (7, 11), (7, 12), (7, 13), (7, 14), (7, 15), (7, 16), (7, 17), (7, 18), (7, 19), (8, 0), (8, 1), (8, 2), (8, 3), (8, 4), (8, 5), (8, 6), (8, 7), (8, 8), (8, 9), (8, 10), (8, 11), (8, 12), (8, 13), (8, 14), (8, 15), (8, 16), (8, 17), (8, 18), (8, 19), (9, 0), (9, 1), (9, 2), (9, 3), (9, 4), (9, 5), (9, 6), (9, 7), (9, 8), (9, 9), (9, 10), (9, 11), (9, 12), (9, 13), (9, 14), (9, 15), (9, 16), (9, 17), (9, 18), (9, 19), (10, 0), (10, 1), (10, 2), (10, 3), (10, 4), (10, 5), (10, 6), (10, 7), (10, 8), (10, 9), (10, 10), (10, 11), (10, 12), (10, 13), (10, 14), (10, 15), (10, 16), (10, 17), (10, 18), (10, 19), (11, 0), (11, 1), (11, 2), (11, 3), (11, 4), (11, 5), (11, 6), (11, 7), (11, 8), (11, 9), (11, 10), (11, 11), (11, 12), (11, 13), (11, 14), (11, 15), (11, 16), (11, 17), (11, 18), (11, 19), (12, 0), (12, 1), (12, 2), (12, 3), (12, 4), (12, 5), (12, 6), (12, 7), (12, 8), (12, 9), (12, 10), (12, 11), (12, 12), (12, 13), (12, 14), (12, 15), (12, 16), (12, 17), (12, 18), (12, 19), (13, 0), (13, 1), (13, 2), (13, 3), (13, 4), (13, 5), (13, 6), (13, 7), (13, 8), (13, 9), (13, 10), (13, 11), (13, 12), (13, 13), (13, 14), (13, 15), (13, 16), (13, 17), (13, 18), (13, 19), (14, 0), (14, 1), (14, 2), (14, 3), (14, 4), (14, 5), (14, 6), (14, 7), (14, 8), (14, 9), (14, 10), (14, 11), (14, 12), (14, 13), (14, 14), (14, 15), (14, 16), (14, 17), (14, 18), (14, 19), (15, 0), (15, 1), (15, 2), (15, 3), (15, 4), (15, 5), (15, 6), (15, 7), (15, 8), (15, 9), (15, 10), (15, 11), (15, 12), (15, 13), (15, 14), (15, 15), (15, 16), (15, 17), (15, 18), (15, 19), (16, 0), (16, 1), (16, 2), (16, 3), (16, 4), (16, 5), (16, 6), (16, 7), (16, 8), (16, 9), (16, 10), (16, 11), (16, 12), (16, 13), (16, 14), (16, 15), (16, 16), (16, 17), (16, 18), (16, 19), (17, 0), (17, 1), (17, 2), (17, 3), (17, 4), (17, 5), (17, 6), (17, 7), (17, 8), (17, 9), (17, 10), (17, 11), (17, 12), (17, 13), (17, 14), (17, 15), (17, 16), (17, 17), (17, 18), (17, 19), (18, 0), (18, 1), (18, 2), (18, 3), (18, 4), (18, 5), (18, 6), (18, 7), (18, 8), (18, 9), (18, 10), (18, 11), (18, 12), (18, 13), (18, 14), (18, 15), (18, 16), (18, 17), (18, 18), (18, 19), (19, 0), (19, 1), (19, 2), (19, 3), (19, 4), (19, 5), (19, 6), (19, 7), (19, 8), (19, 9), (19, 10), (19, 11), (19, 12), (19, 13), (19, 14), (19, 15), (19, 16), (19, 17), (19, 18), (19, 19)] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "None <class 'NoneType'>\n",
      "True <class 'bool'>\n",
      "A <class 'str'>\n",
      "False <class 'bool'>\n",
      "False <class 'bool'>\n",
      "[(3, 20, 20), (3, 18, 18), (3, 16, 16), (3, 14, 14), (3, 12, 12), 100, 200, 4] <class 'list'>\n",
      "['conv', 'pool', 'conv', 'pool', 'linear', 'linear'] <class 'list'>\n",
      "0.98 <class 'float'>\n",
      "0.0005 <class 'float'>\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ") <class 'torch.optim.adam.Adam'>\n",
      "None <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "def data_log(run_id, experiment_type, experiment, **kwargs):\n",
    "    load_from = kwargs.get('load_from',' ')\n",
    "    expt_log = [\n",
    "    'save_id',          #uuid\n",
    "    'experiment_type',  #int\n",
    "    'load_from',        #str\n",
    "    'num_trials',       #int\n",
    "    'num_events',       #int\n",
    "    'ENVIRONMENT',      #str\n",
    "    'shape',            #tuple \n",
    "    'rho',              #float\n",
    "    'rewards',          #dict\n",
    "    'action_list',      #list\n",
    "    'rwd_action',       #str\n",
    "    'step_penalization',#float\n",
    "    'useable',          #list\n",
    "    'obstacle2D',       #list\n",
    "    'terminal2D',       #list\n",
    "    'jump',             #list or NoneType\n",
    "    'random_start',     #bool\n",
    "    'AGENT',            #arch \n",
    "    'use_SR',           #bool\n",
    "    'freeze_weights',   #bool\n",
    "    'layers',           #list\n",
    "    'hidden_types',     #list\n",
    "    'gamma',            #float\n",
    "    'eta',              #float\n",
    "    'optimizer',        #torch optim. class\n",
    "    'MEMORY', #         # string* \n",
    "    'cache_limit',      #int\n",
    "    'use_pvals',        #bool\n",
    "    'memory_envelope',  #int\n",
    "    'mem_temp',         #float\n",
    "    'alpha',            #float   # memory mixing parameters\n",
    "    'beta'              #int\n",
    "    ]\n",
    "    write = kwargs.get('write', False)  \n",
    "    \n",
    "    \n",
    "    \n",
    "    log_jam = [\n",
    "        run_id,\n",
    "        experiment_type, \n",
    "        load_from,\n",
    "        experiment.num_trials,\n",
    "        experiment.num_events,\n",
    "        \n",
    "        str(experiment.env.maze_type), # 'ENVIRONMENT'\n",
    "        experiment.env.shape,\n",
    "        float(experiment.env.rho),\n",
    "        experiment.env.rewards,\n",
    "        experiment.env.action_list,\n",
    "        experiment.env.rwd_action,\n",
    "        experiment.env.step_penalization,\n",
    "        experiment.env.useable,\n",
    "        experiment.env.obstacle2D,\n",
    "        experiment.env.terminal2D,\n",
    "        experiment.env.jump,\n",
    "        experiment.env.random_start,\n",
    "        \n",
    "        experiment.agent_architecture, #'AGENT'\n",
    "        experiment.agent.use_SR,\n",
    "        experiment.agent.optimizer.param_groups[0]['lr'] == 0.0, # evaluates true if frozen weights\n",
    "        experiment.agent.layers,\n",
    "        experiment.agent.hidden_types,\n",
    "        experiment.agent.gamma,\n",
    "        experiment.agent.eta,\n",
    "        experiment.agent.optimizer,\n",
    "        \n",
    "        str(experiment.episodic)\n",
    "    ]\n",
    "    \n",
    "    if experiment.episodic is not None: \n",
    "        epi_log = [\n",
    "            experiment.episodic.cache_limit,\n",
    "            experiment.episodic.use_pvals,\n",
    "            experiment.episodic.mem_temp,\n",
    "            experiment.alpha,\n",
    "            experiment.beta\n",
    "        ]\n",
    "        log_jam += epi_log\n",
    "    for i in log_jam:\n",
    "        print(i, type(i))\n",
    "    if write:\n",
    "        parent_folder = '../data/outputs/gridworld/E2'\n",
    "        # write to logger\n",
    "        with open(f'{parent_folder}/experiments_log.csv', 'a+', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(log_jam)\n",
    "        \n",
    "        # save environment\n",
    "        if experiment_type == 0: \n",
    "            pickle.dump(experiment.env, open(f'{parent_folder}/environments/{save_id}_env.p', 'wb'))\n",
    "        \n",
    "        # save agent\n",
    "        torch.save(experiment.agent, f'{parent_folder}/agent_weights/{save_id}.pt')\n",
    "        # save data\n",
    "        pickle.dump(experiment.data, open(f'{parent_folder}/results/{save_id}_data.p', 'wb'))\n",
    "        # save memory\n",
    "        if experiment.episodic is not None:\n",
    "            pickle.dump(experiment.episodic, open(f'{parent_folder}/episodic_memory/{save_id}_EC.p', 'wb'))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "data_log(save_id, ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rewards = {(5,15):1}\n",
    "env.buildRewardFunction()\n",
    "fig = gw.plotWorld(env, scale=0.3, four_actions=(len(env.action_list) == 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([agent.optimizer.param_groups[x]['lr'] for x in range(len(agent.optimizer.param_groups))])\n",
    "print(ex.episodic)\n",
    "print(agent_params['use_EC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Environment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(expt)\n",
    "\n",
    "alphas = np.arange(1,6)*0.1\n",
    "betas = np.arange(0,50,10)\n",
    "betas[0] =1 \n",
    "\n",
    "experiment_type = 0\n",
    "if experiment_type is not 0: \n",
    "    id_key = input('Weights to load: ')\n",
    "    agent_params[experiment_type]['load_dir'] = f'../data/outputs/gridworld/weights/{id_key}.pt',\n",
    "    print(agent_params[experiment_type]['load_dir'])\n",
    "\n",
    "    \n",
    "for j in range(1):\n",
    "    for alpha in alphas:\n",
    "        for beta in [5]:\n",
    "            print(f'alpha:{alpha},beta:{beta}')\n",
    "            # generate agent from given parameters\n",
    "            agent = ac.make_agent(agent_params[experiment_type])\n",
    "            print(agent)\n",
    "\n",
    "            \n",
    "\n",
    "            # get unique ID tag for this run\n",
    "            save_id = uuid.uuid4()\n",
    "\n",
    "            ex = expt.test_expt(agent, env, use_mem=agent_params[experiment_type]['use_EC'])\n",
    "            #ex.run(NUM_TRIALS, 50, data, alpha=alpha,beta=beta)\n",
    "\n",
    "\n",
    "            if agent_params[experiment_type]['use_EC']:\n",
    "                mem = ex.episodic\n",
    "            else:\n",
    "                mem = None\n",
    "            if agent.use_SR:\n",
    "                arch = 'B'\n",
    "            else: \n",
    "                arch = 'A'\n",
    "                \n",
    "            #expt.log_experiments(save_id, experiment_type, \n",
    "            #                     env, agent, data, mem, \n",
    "            #                     save_flag = True, \n",
    "            #                     load=agent_params[experiment_type]['load_dir'], arch = arch,\n",
    "            #                    alpha=alpha, beta=beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing = 30\n",
    "plt.figure()\n",
    "plt.plot(gp.running_mean(data['total_reward'],smoothing),'pink')\n",
    "plt.title('Smoothed Reward Per Trial')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "#plt.plot(gp.running_mean(data['loss'][0],smoothing), 'darkgreen', label='$\\pi$')\n",
    "#plt.plot(gp.running_mean(data['loss'][1],smoothing), 'lightgreen', label='v')\n",
    "plt.plot(gp.running_mean(data['loss'][2],smoothing), 'cyan', label='$\\phi$')\n",
    "plt.legend(loc=0)\n",
    "plt.title('Smoothed Loss')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reload(expt)\n",
    "\n",
    "sample_observations = env.get_sample_obs()\n",
    "pol_grid, val_grid = expt.get_snapshot(sample_observations, env,agent)\n",
    "gp.plot_pref_pol(env, pol_grid, threshold = 0.1, title='ec_pol_new_rwd',upperbound=2)\n",
    "gp.plot_polmap(env, pol_grid, threshold = 0.22)\n",
    "gp.plot_valmap(env, val_grid, v_range = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['trials_run_to_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = f'../data/outputs/gridworld/weights/{save_id}.pt'\n",
    "ac.torch.save(agent,save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(gp)\n",
    "def ec_policies(maze, EC, trial_timestamp,**kwargs):\n",
    "    envelope = kwargs.get('decay', 50)\n",
    "    mem_temp = kwargs.get('mem_temp', 1)\n",
    "    mpol_array = np.zeros(maze.grid.shape, dtype=[(x, 'f8') for x in maze.action_list])\n",
    "    \n",
    "    # cycle through readable states\n",
    "    for key in EC.cache_list.keys():\n",
    "        row, col = EC.cache_list[key][2]\n",
    "        pol = EC.recall_mem(key, timestep = trial_timestamp, mem_temp = mem_temp, print_t=False)\n",
    "        mpol_array[row,col] = tuple(pol)\n",
    "        \n",
    "    return mpol_array\n",
    "        \n",
    "\n",
    "abcd = ec_policies(env,ex.episodic, trial_timestamp = 0, mem_temp = 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(gp)\n",
    "gp.plot_pref_pol(env, abcd, threshold = 0.1, title='ec_pol_new_rwd',upperbound=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = (4,3)\n",
    "env.set_state(env.twoD2oneD(state))\n",
    "observation = torch.Tensor(np.expand_dims(env.get_observation(), axis=0))\n",
    "policy_, value_, phi_, psi_ = agent(observation)\n",
    "\n",
    "lin_act = tuple(np.round(phi_.data[0].numpy(),4))\n",
    "key, sim = ex.episodic.cosine_sim(lin_act)\n",
    "\n",
    "mem_state = ex.episodic.cache_list[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mem_state)\n",
    "print(ex.episodic.recall_mem(lin_act, timestep=0))\n",
    "#print(abcd[state])\n",
    "plt.bar(np.arange(4),ex.episodic.recall_mem(lin_act, timestep=0))\n",
    "#MF_alone = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.mem_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random events \n",
    "sig = 0.8\n",
    "rewards = np.array([np.random.choice([0,1], p=[sig, 1-sig]) for x in range(100)], dtype=float)\n",
    "rewards[np.where(rewards==0)] = -0.01\n",
    "\n",
    "print(rewards)\n",
    "\n",
    "def poops(x, alpha, beta):    \n",
    "    toots = alpha*np.exp(-np.arange(len(x))/beta) # exponential decay with time \n",
    "    poops = np.convolve(toots,x, mode='full')[0:len(x)]\n",
    "    return poops\n",
    "\n",
    "def turds(x, alpha, beta):\n",
    "    #alpha = bump size\n",
    "    # beta = number of steps to decay to 0.01\n",
    "    threshold = 0.01\n",
    "    decay = np.power(threshold,1/beta)\n",
    "    a = np.empty_like(x, dtype=float)\n",
    "    \n",
    "    for ind, i in enumerate(x):\n",
    "        if ind == 0:\n",
    "            a[ind] = i*alpha\n",
    "        else:\n",
    "            calc = decay*a[ind-1] + i*alpha\n",
    "            if calc > 1:\n",
    "                calc = 1\n",
    "            a[ind] = calc\n",
    "    return a\n",
    "\n",
    "alphas = np.arange(1,6)*0.1\n",
    "betas = np.arange(0,50,10)\n",
    "betas[0] = 1\n",
    "## iterate over alphas: \n",
    "fig, ax = plt.subplots(len(alphas), 1, sharex=True, sharey=True)\n",
    "for xx, i in enumerate(alphas):\n",
    "    for j in betas:\n",
    "        pp = turds(rewards,alpha=i,beta=j)\n",
    "        ax[xx].plot(rewards,'k|')\n",
    "        ax[xx].plot(pp,label=f'b={j}')\n",
    "        ax[xx].set_ylabel(f'a={np.round(i,2)}')\n",
    "        \n",
    "ax[0].legend(bbox_to_anchor=(1.05,0.95))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# iterate over betas:\n",
    "fig, ax = plt.subplots(len(betas),1, sharex=True, sharey=True)\n",
    "for yy, j in enumerate(betas):\n",
    "    for i in alphas:\n",
    "        pp = turds(rewards,alpha=i, beta=j)\n",
    "        ax[yy].plot(rewards,'k|')\n",
    "        ax[yy].plot(pp,label=f'a={i}')\n",
    "        ax[yy].set_ylabel(f'b={np.round(j,2)}')\n",
    "ax[0].legend(bbox_to_anchor=(1.05,0.95))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
